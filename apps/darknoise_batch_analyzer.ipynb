{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import math\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from reportlab.lib import colors\n",
    "import tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from massibo_ana.core.WaveformSet import WaveformSet\n",
    "from massibo_ana.core.DarkNoiseMeas import DarkNoiseMeas\n",
    "from massibo_ana.postprocess.PDFGenerator import PDFGenerator\n",
    "import massibo_ana.utils.search as search\n",
    "import massibo_ana.utils.custom_exceptions as cuex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load the input parameters and change the WD to the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write here the ABSOLUTE path to the input parameters file\n",
    "input_parameters_filepath = ''\n",
    "\n",
    "with open(\n",
    "        input_parameters_filepath,\n",
    "        \"r\",\n",
    "        encoding=\"utf-8\"\n",
    "    ) as file:\n",
    "        \n",
    "        params = yaml.safe_load(file)\n",
    "\n",
    "os.chdir(params['workspace_dir'])\n",
    "load_dir = \"load/\"\n",
    "summary_dir = \"summary/\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Read the waveforms, rebin, compute baseline and flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darknoisemeas_objects = tools.build_list_of_SiPMMeas_objects(\n",
    "    load_dir,\n",
    "    params['strips_to_analyze'],\n",
    "    params['analyzable_marks'],\n",
    "    is_gain_meas=False,\n",
    "    verbose=params['verbose']\n",
    ")\n",
    "\n",
    "if len(darknoisemeas_objects) == 0:\n",
    "    raise Exception(\n",
    "        \"Not a single DarkNoiseMeas object was found coming from \"\n",
    "        f\"a board with a strip ID within {params['strips_to_analyze']} \"\n",
    "        f\"and with a mark within {params['analyzable_marks']}.\"\n",
    "    )\n",
    "\n",
    "for dno in darknoisemeas_objects:\n",
    "    \n",
    "    dno.rebin(params['merged_points'])\n",
    "\n",
    "    # The baseline needs to be computed prior to\n",
    "    # integrating the waveforms during the integral filter\n",
    "    dno.Waveforms.compute_first_peak_baseline(\n",
    "    signal_fraction_for_median_cutoff=params['signal_fraction_for_median_cutoff']\n",
    "    )\n",
    "\n",
    "    if params['flip_about_baseline']:\n",
    "        dno.Waveforms.flip_about_baseline()\n",
    "\n",
    "# Order the waveform sets according to their strip IDs\n",
    "darknoisemeas_objects = tools.order_list_of_SiPMMeas_objects(darknoisemeas_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Start the PDF report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params['generate_report']:\n",
    "\n",
    "    pdf_chunks_filepaths_generator = PDFGenerator.PDF_chunk_filepath(\n",
    "        summary_dir,\n",
    "        params['report_output_filename']\n",
    "    )\n",
    "    \n",
    "    aux = next(pdf_chunks_filepaths_generator)\n",
    "    pdf_reports_filepaths = [aux]\n",
    "    report_pdf = PDFGenerator(aux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Apply offline filter (WaveformSet.integral_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The analysis reliability parameter is set to 3 by default,\n",
    "# which is the maximum reliability level. If after the\n",
    "# offline filter, the number of waveforms for a certain SiPM\n",
    "# is less than the minimum_number_of_well_formed_waveforms\n",
    "# parameter, the reliability parameter for such SiPM is set\n",
    "# to 0. If the analysis failed (particularly, the 0-PE and 1-PE\n",
    "# amplitude-peaks fit, required for the 0.5- and 1.5-PE levels\n",
    "# computation) the reliability is set to 1. If after the bursts\n",
    "# purge, the number of waveforms for a certain SiPM is less\n",
    "# than the minimum_number_of_non_burst_waveforms parameter, the\n",
    "# reliability parameter for such SiPM is set to 2.\n",
    "# Long story short, if the analysis breaks in the filter (first\n",
    "# stage), the reliability is set to 0. If it breaks in the fit\n",
    "# (second stage), the reliability is set to 1. If it breaks in\n",
    "# the bursts purge (third stage), the reliability is set to 2.\n",
    "# If everything went OK, the reliability remains set to 3.\n",
    "analysis_reliability = [3] * len(darknoisemeas_objects)\n",
    "\n",
    "filtered_dnos = []\n",
    "for i in range(len(darknoisemeas_objects)):\n",
    "\n",
    "    if params['verbose']:\n",
    "        print(\n",
    "            f\"Deep-copying the {i+1}-th \"\n",
    "            f\"(/{len(darknoisemeas_objects)}) SiPM data \"\n",
    "            f\"- {darknoisemeas_objects[i].get_title()}\"\n",
    "        )\n",
    "\n",
    "    # The filtered version of darknoisemeas_objects[i] is filtered_dnos[i]\n",
    "    filtered_dnos.append(copy.deepcopy(darknoisemeas_objects[i]))\n",
    "\n",
    "noise_idcs = {}\n",
    "for idx in range(len(filtered_dnos)):\n",
    "\n",
    "    # dno is a view to filtered_dnos[idx]\n",
    "    dno = filtered_dnos[idx]\n",
    "\n",
    "    if params['verbose']:\n",
    "        print(\n",
    "            f\"Filtering the {idx+1}-th (/\"\n",
    "            f\"{len(filtered_dnos)}) SiPM data - {dno.get_title()}\"\n",
    "        )\n",
    "\n",
    "    wvfs_no = len(dno.Waveforms)\n",
    "    # Assuming every waveform in dno.Waveforms\n",
    "    # has the same number of data points\n",
    "    points_per_wvf = len(dno.Waveforms[0].Signal)\n",
    "\n",
    "    # Assuming that the Time attribute is the same\n",
    "    # for all waveforms in the same DarkNoiseMeas object\n",
    "    aux, _ = search.find_nearest_neighbour(\n",
    "        dno.Waveforms[0].Time,\n",
    "        params['window_start_s']\n",
    "    )\n",
    "        \n",
    "    noise_idcs[idx] = dno.Waveforms.filter(\n",
    "        WaveformSet.integral_filter,\n",
    "        # This one is given as an arg to the filter function\n",
    "        params['minimum_integral'],\n",
    "        return_idcs=True,\n",
    "        purge=True,\n",
    "        ask_for_confirmation=False,\n",
    "        # Given as a kwarg to the filter function\n",
    "        i0=aux,\n",
    "        # delta_t=dno.Waveforms[i].find_beginning_of_rise(\n",
    "        #     tolerance=params['tolerance_for_beginning_of_rise'],\n",
    "        #     return_iterator=False\n",
    "        # )+params['delta_t_from_beginning_of_rise'],\n",
    "        delta_t=params['integral_window_width_s'],\n",
    "        also_return_integral=False\n",
    "    )\n",
    "\n",
    "    if params['verbose']:\n",
    "        print(\n",
    "            \"Eliminated \"\n",
    "            f\"{round(100.*len(noise_idcs[idx])/len(darknoisemeas_objects[idx].Waveforms), ndigits=2)}\"\n",
    "            \"% of the fast frames\"\n",
    "        )\n",
    "    \n",
    "    if len(dno.Waveforms) < params['minimum_number_of_well_formed_waveforms']:\n",
    "        analysis_reliability[idx] = 0\n",
    "\n",
    "        if params['verbose']:\n",
    "            print(\n",
    "                f\"WARNING: Only {len(dno.Waveforms)} waveforms \"\n",
    "                f\"(< {params['minimum_number_of_well_formed_waveforms']}) \"\n",
    "                \"were left after filtering the noise-induced triggers. \"\n",
    "                \"The analysis for this SiPM has been tagged as 0-reliable.\"\n",
    "            )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Run the peak detection algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(filtered_dnos)):\n",
    "\n",
    "    minimum_peak_width_in_samples = math.floor(\n",
    "        params['minimum_peak_width_in_s']/(filtered_dnos[idx].Sampling_ns*1e-9)\n",
    "    )\n",
    "\n",
    "    if params['verbose']:\n",
    "        print(\n",
    "            f\"Detecting peaks for the {idx+1}-th (/\"\n",
    "            f\"{len(filtered_dnos)}) SiPM data - {filtered_dnos[idx].get_title()}\"\n",
    "        )\n",
    "\n",
    "    filtered_dnos[idx].Waveforms.find_peaks(\n",
    "        height=params['minimal_height_wrt_baseline_in_AU'],\n",
    "        prominence=params['minimum_peaks_prominence'],\n",
    "        width=minimum_peak_width_in_samples,\n",
    "        rel_height=params['rel_height_for_peak_width'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Report results of offline filter and the peak-detection algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params['generate_report']:\n",
    "\n",
    "    # Number of accepted-waveforms persistency plots\n",
    "    # It is also the number of rejected-waveforms\n",
    "    # persistency plots. Setting this parameter to a value\n",
    "    # other than 2 would break the report PDF layout.\n",
    "    steps = 2\n",
    "\n",
    "    # Number of grid-plots per SiPM. Setting this\n",
    "    # parameter to a value other than 2 would break\n",
    "    # the report PDF layout.\n",
    "    canvases_to_show_per_sipm = 2\n",
    "\n",
    "    # Number of rows and columns in each grid-plot.\n",
    "    # Setting these parameter to a value other than\n",
    "    # (3, 5) would break the report PDF layout.\n",
    "    nrows = 3\n",
    "    ncols = 5\n",
    "\n",
    "    for idx in range(len(darknoisemeas_objects)):\n",
    "\n",
    "        if params['verbose']:\n",
    "            print(\n",
    "                \"Reporting the offline-filter results for \"\n",
    "                f\"the {idx+1}-th (/{len(filtered_dnos)}) SiPM \"\n",
    "                f\"data - {filtered_dnos[idx].get_title()}\"\n",
    "            )\n",
    "\n",
    "        report_pdf.add_text(\n",
    "            # filtered_dnos preserve the ordering of darknoisemeas_objects\n",
    "            f\"Iterator {idx}, {darknoisemeas_objects[idx].get_title()}\",\n",
    "            horizontal_pos_frac=None,\n",
    "            vertical_pos_frac=0.95,\n",
    "            max_width_frac=0.9,\n",
    "            font_size=params['title_font_size'],\n",
    "            horizontally_center=True\n",
    "        )\n",
    "\n",
    "        report_pdf.add_text(\n",
    "            f\"Offline filter results\",\n",
    "            horizontal_pos_frac=None,\n",
    "            vertical_pos_frac=0.88,\n",
    "            max_width_frac=0.9,\n",
    "            font_size=params['subtitle_font_size'],\n",
    "            horizontally_center=True\n",
    "        )\n",
    "\n",
    "        report_pdf.add_text(\n",
    "            f\"Filtered out {len(noise_idcs[idx])} out of \"\n",
    "            f\"{len(darknoisemeas_objects[idx].Waveforms)} \"\n",
    "            f\"fast frames (i.e. {round(100.*len(noise_idcs[idx])/len(darknoisemeas_objects[idx].Waveforms), ndigits=2)}\"\n",
    "            f\"% of the fast frames), leaving {len(filtered_dnos[idx].Waveforms)} waveforms for the analysis\",\n",
    "            horizontal_pos_frac=None,\n",
    "            vertical_pos_frac=0.84,\n",
    "            max_width_frac=0.9,\n",
    "            font_size=params['text_font_size'],\n",
    "            horizontally_center=True\n",
    "        )\n",
    "\n",
    "        if analysis_reliability[idx] < 1:\n",
    "            report_pdf.add_text(\n",
    "                f\"WARNING: The analysis for this SiPM has \"\n",
    "                \"been tagged as 0-reliable because the filter \"\n",
    "                f\"left less than {params['minimum_number_of_well_formed_waveforms']}\"\n",
    "                \" waveforms\",\n",
    "                horizontal_pos_frac=0.40,\n",
    "                vertical_pos_frac=0.89,\n",
    "                max_width_frac=0.6,\n",
    "                font_size=params['text_font_size']-2,\n",
    "                font_color=colors.red,\n",
    "                horizontally_center=False\n",
    "            )\n",
    "\n",
    "        dno = filtered_dnos[idx]\n",
    "        for i in range(steps):\n",
    "\n",
    "            aux = dno.Waveforms.plot(\n",
    "                # Plot the filtered dataset\n",
    "                wvfs_to_plot=list(\n",
    "                    range(\n",
    "                        i*params['wvfs_per_step'],\n",
    "                        (i+1)*params['wvfs_per_step']\n",
    "                    )\n",
    "                ) if (i+1)*params['wvfs_per_step'] <= len(dno.Waveforms) else\n",
    "                list(\n",
    "                    range(\n",
    "                        i*params['wvfs_per_step'],\n",
    "                        len(dno.Waveforms)\n",
    "                    )\n",
    "                ),\n",
    "                plot_peaks=False,\n",
    "                fig_title=f\"Accepted frames ({params['wvfs_per_step']} samples)\"\n",
    "                if (i+1)*params['wvfs_per_step'] <= len(dno.Waveforms) else\n",
    "                f\"Accepted frames ({len(dno.Waveforms) - (i * params['wvfs_per_step'])} samples)\",\n",
    "                mode='superposition',\n",
    "                title_fontsize=params['title_font_size'],\n",
    "                wvf_linewidth=params['persistency_wvf_linewidth'],\n",
    "                subtract_baseline=True,\n",
    "                show_plots=False\n",
    "            )\n",
    "            report_pdf.add_plot(\n",
    "                aux[0],\n",
    "                horizontal_pos_frac=0.01 if i == 0 else 0.26,\n",
    "                vertical_pos_frac=0.45,\n",
    "                plot_width_wrt_page_width=0.25,\n",
    "                horizontally_center=False\n",
    "            )\n",
    "\n",
    "        dno = darknoisemeas_objects[idx]\n",
    "        idcs_to_plot = noise_idcs[idx]\n",
    "        for i in range(steps):\n",
    "\n",
    "            aux = dno.Waveforms.plot(\n",
    "                # Plot the selected indices from the unfiltered dataset\n",
    "                wvfs_to_plot=idcs_to_plot[i*params['wvfs_per_step']:(i+1)*params['wvfs_per_step']]\n",
    "                if (i+1)*params['wvfs_per_step'] <= len(idcs_to_plot) else\n",
    "                idcs_to_plot[i*params['wvfs_per_step']:],\n",
    "                plot_peaks=False,\n",
    "                fig_title=f\"Rejected frames ({params['wvfs_per_step']} samples)\"\n",
    "                if (i+1)*params['wvfs_per_step'] <= len(idcs_to_plot) else\n",
    "                f\"Rejected frames ({len(idcs_to_plot) - (i * params['wvfs_per_step'])} samples)\",\n",
    "                mode='superposition',\n",
    "                title_fontsize=params['title_font_size'],\n",
    "                wvf_linewidth=params['persistency_wvf_linewidth'],\n",
    "                subtract_baseline=True,\n",
    "                show_plots=False\n",
    "            )\n",
    "            \n",
    "            report_pdf.add_plot(\n",
    "                aux[0],\n",
    "                horizontal_pos_frac=0.51 if i == 0 else 0.76,\n",
    "                vertical_pos_frac=0.45,\n",
    "                plot_width_wrt_page_width=0.25,\n",
    "                horizontally_center=False\n",
    "            )\n",
    "            \n",
    "            if (i+1)*params['wvfs_per_step'] > len(idcs_to_plot):\n",
    "                break\n",
    "\n",
    "        if params['verbose']:\n",
    "            print(\n",
    "                \"Reporting the peak-detection results for \"\n",
    "                f\"the {idx+1}-th (/{len(filtered_dnos)}) \"\n",
    "                f\"SiPM data - {filtered_dnos[idx].get_title()}\"\n",
    "            )\n",
    "\n",
    "        report_pdf.add_text(\n",
    "            f\"Some peak-detection examples\",\n",
    "            horizontal_pos_frac=None,\n",
    "            vertical_pos_frac=0.63,\n",
    "            max_width_frac=0.9,\n",
    "            font_size=params['subtitle_font_size'],\n",
    "            horizontally_center=True\n",
    "        )\n",
    "\n",
    "        if len(filtered_dnos[idx].Waveforms) > 0:\n",
    "\n",
    "            aux = filtered_dnos[idx].Waveforms.plot(\n",
    "                wvfs_to_plot=min(\n",
    "                    canvases_to_show_per_sipm * nrows * ncols,\n",
    "                    len(filtered_dnos[idx].Waveforms)\n",
    "                ), \n",
    "                plot_peaks=True,\n",
    "                wvf_linewidth=0.2,\n",
    "                x0=[],\n",
    "                y0=[],\n",
    "                randomize=True,\n",
    "                fig_title=None,\n",
    "                mode='grid',\n",
    "                nrows=nrows,\n",
    "                ncols=ncols,\n",
    "                fig_width=10.,\n",
    "                fig_height=5.0,\n",
    "                show_plots=False\n",
    "            )\n",
    "\n",
    "            for i in range(\n",
    "                min(\n",
    "                    canvases_to_show_per_sipm,\n",
    "                    len(aux)\n",
    "                )\n",
    "            ):\n",
    "                report_pdf.add_plot(\n",
    "                    aux[i],\n",
    "                    horizontal_pos_frac=None,\n",
    "                    # Assuming the number of canvases\n",
    "                    # to show per SiPM is 2\n",
    "                    vertical_pos_frac={\n",
    "                        0: 0.18,\n",
    "                        1: -0.1\n",
    "                    }[i],\n",
    "                    plot_width_wrt_page_width=0.8,\n",
    "                    horizontally_center=True\n",
    "                )\n",
    "        else:\n",
    "            report_pdf.add_text(\n",
    "                \"WARNING: The offline filter left no waveforms \"\n",
    "                \"for this SiPM. There are no peak-detection \"\n",
    "                \"results\",\n",
    "                horizontal_pos_frac=None,\n",
    "                vertical_pos_frac=0.35,\n",
    "                max_width_frac=0.9,\n",
    "                font_size=params['text_font_size'],\n",
    "                font_color=colors.red,\n",
    "                horizontally_center=True\n",
    "            )\n",
    "    \n",
    "        started_a_new_pdf, aux = PDFGenerator.smart_close_page(\n",
    "            report_pdf,\n",
    "            params['max_pages_per_pdf_chunk'],\n",
    "            pdf_chunks_filepaths_generator\n",
    "        )\n",
    "\n",
    "        if started_a_new_pdf:\n",
    "            del report_pdf\n",
    "            report_pdf = aux\n",
    "            pdf_reports_filepaths.append(report_pdf.OutputFilepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Run the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(filtered_dnos)):\n",
    "\n",
    "    if analysis_reliability[idx] < 1:\n",
    "        if params['verbose']:\n",
    "            print(\n",
    "                f\"Skipping the levels analysis for the {idx+1}-th \"\n",
    "                f\"(/{len(filtered_dnos)}) (0-reliable) SiPM data - \"\n",
    "                f\"{filtered_dnos[idx].get_title()}\"\n",
    "            )\n",
    "        continue\n",
    "    else:\n",
    "        if params['verbose']:\n",
    "            print(\n",
    "                f\"Computing the 0.5- and 1.5-PE levels for the \"\n",
    "                f\"{idx+1}-th (/{len(filtered_dnos)}) SiPM data - \"\n",
    "                f\"{filtered_dnos[idx].get_title()}\"\n",
    "            )\n",
    "    try:\n",
    "        filtered_dnos[idx].analyze(\n",
    "            peaks_to_detect=2,\n",
    "            bins_no=params['amplitudes_histogram_bins_no'],\n",
    "            starting_fraction=params['starting_fraction'],\n",
    "            step_fraction=params['step_fraction'],\n",
    "            # You may need to tune this one to avoid labelling\n",
    "            # as an ill-formed case a SiPM with very low XTP \n",
    "            # (so low that the second peak in the amplitude \n",
    "            # histogram is very small so as to be ruled out \n",
    "            # by the prominence cut)\n",
    "            minimal_prominence_wrt_max=params['minimal_prominence_wrt_max'],\n",
    "            std_no=params['gaussian_fit_std_no'],\n",
    "            timedelay_cut=params['timedelay_cut']\n",
    "        )\n",
    "    except RuntimeError:\n",
    "        try: \n",
    "            print(\n",
    "                f\"WARNING: Got a RuntimeError when processing \"\n",
    "                f\"the {idx+1}-th SiPM data. Now trying to reanalyze \"\n",
    "                f\"it using a softer prominence (minimal_prominence_wrt_max = \"\n",
    "                f\"{params['minimal_prominence_wrt_max']} -> \"\n",
    "                f\"{params['minimal_prominence_wrt_max'] - (0.25 * params['minimal_prominence_wrt_max'])})\"\n",
    "                \" requirement.\"\n",
    "            )\n",
    "            filtered_dnos[idx].analyze(\n",
    "                peaks_to_detect=2,\n",
    "                bins_no=params['amplitudes_histogram_bins_no'],\n",
    "                starting_fraction=params['starting_fraction'],\n",
    "                step_fraction=params['step_fraction'],\n",
    "                # Decrease the required prominence for the peaks\n",
    "                # to be detected by a 25% of the original value\n",
    "                minimal_prominence_wrt_max=params['minimal_prominence_wrt_max'] \n",
    "                - 0.25 * params['minimal_prominence_wrt_max'],\n",
    "                std_no=params['gaussian_fit_std_no'],\n",
    "                timedelay_cut=params['timedelay_cut']\n",
    "            )\n",
    "\n",
    "            print(\n",
    "                f\"Re-analysis of the {idx+1}-th SiPM data \"\n",
    "                \"executed normally.\"\n",
    "            )\n",
    "\n",
    "        except RuntimeError:\n",
    "            print(\n",
    "                f\"WARNING: Still got a RuntimeError when re-processing \"\n",
    "                f\"the {idx+1}-th SiPM data. The analysis for this \"\n",
    "                \"SiPM has been tagged as 1-reliable.\"\n",
    "            )\n",
    "            analysis_reliability[idx] = 1\n",
    "            continue\n",
    "\n",
    "    except cuex.RestrictiveTimedelay:\n",
    "\n",
    "        print(\n",
    "            f\"WARNING: Got a cuex.RestrictiveTimedelay exception \"\n",
    "            f\"when processing the {idx+1}-th SiPM data. Now \"\n",
    "            \"reanalyzing it using a softer cut for the timedelay \"\n",
    "            f\"(timedelay_cut = {params['timedelay_cut']} -> {params['timedelay_cut']/10.}).\"\n",
    "        )\n",
    "        \n",
    "        filtered_dnos[idx].analyze(\n",
    "            peaks_to_detect=2,\n",
    "            bins_no=params['amplitudes_histogram_bins_no'],\n",
    "            starting_fraction=params['starting_fraction'],\n",
    "            step_fraction=params['step_fraction'],\n",
    "            # Decrease the required prominence for the peaks\n",
    "            # to be detected by a 25% of the original value\n",
    "            minimal_prominence_wrt_max=params['minimal_prominence_wrt_max'],\n",
    "            std_no=params['gaussian_fit_std_no'],\n",
    "            timedelay_cut=params['timedelay_cut']/10.\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"Re-analysis of the {idx+1}-th SiPM data \"\n",
    "            \"executed normally.\"\n",
    "        )\n",
    "\n",
    "    # When scipy.optimize.curve_fit() throws an exception message\n",
    "    # a la \"Improper input: func input vector length N=3 must not exceed\n",
    "    # func output vector length M=1\", SiPMMeas.piecewise_gaussian_fits()\n",
    "    # raises a cuex.NotEnoughFitSamples exception. A cause for this is\n",
    "    # that the number of points-to-fit given to scipy.optimize.curve_fit()\n",
    "    # is smaller than than the number of fitting parameters. In our\n",
    "    # particular context, this could have happened because the value\n",
    "    # given to the std_no parameter of DarkNoiseMeas.analyze(), which is\n",
    "    # eventually given to SiPMMeas.piecewise_gaussian_fits() is so small\n",
    "    # that the number of points-to-fit is smaller than the number of\n",
    "    # fitting parameters. \n",
    "    except cuex.NotEnoughFitSamples:\n",
    "\n",
    "        print(\n",
    "            f\"WARNING: Got a cuex.NotEnoughFitSamples exception \"\n",
    "            f\"when processing the {idx+1}-th SiPM data. Now reanalyzing \"\n",
    "            f\"it using a bigger fitting range (std_no = {params['gaussian_fit_std_no']} -> \"\n",
    "            f\"{params['gaussian_fit_std_no']+1.}).\"\n",
    "        )\n",
    "        \n",
    "        filtered_dnos[idx].analyze(\n",
    "            peaks_to_detect=2,\n",
    "            bins_no=params['amplitudes_histogram_bins_no'],\n",
    "            starting_fraction=params['starting_fraction'],\n",
    "            step_fraction=params['step_fraction'],\n",
    "            minimal_prominence_wrt_max=params['minimal_prominence_wrt_max'],\n",
    "            std_no=params['gaussian_fit_std_no']+1.,\n",
    "            timedelay_cut=params['timedelay_cut']\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Report the analysis results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params['generate_report']:\n",
    "\n",
    "    # The values given to these parameters fit\n",
    "    # the layout of the report PDF.\n",
    "    # Number of rows and columns in each grid-plot\n",
    "    rows_per_canvas = 2\n",
    "    cols_per_canvas = 3\n",
    "\n",
    "    axes_per_canvas = rows_per_canvas*cols_per_canvas\n",
    "    objects_to_plot = len(filtered_dnos)\n",
    "    canvases_no = math.ceil(objects_to_plot/axes_per_canvas)\n",
    "\n",
    "    figs, axes = [], []\n",
    "    for i in range(canvases_no):\n",
    "        aux_fig, aux_ax = plt.subplots(\n",
    "            nrows=rows_per_canvas, \n",
    "            ncols=cols_per_canvas\n",
    "        )\n",
    "        aux_fig.set_figheight(6)\n",
    "        aux_fig.set_figwidth(10)\n",
    "        figs.append(aux_fig)\n",
    "        axes.append(aux_ax)\n",
    "        aux_fig.tight_layout()\n",
    "\n",
    "    for i in range(len(filtered_dnos)):\n",
    "\n",
    "        if analysis_reliability[i] < 1:\n",
    "            if params['verbose']:\n",
    "                print(\n",
    "                    \"Skipping the timedelay vs. amplitude plot \"\n",
    "                    f\"for the {i+1}-th (/{len(filtered_dnos)}) \"\n",
    "                    f\"(0-reliable) SiPM data - {filtered_dnos[i].get_title()}\"\n",
    "                )\n",
    "            continue\n",
    "        else:\n",
    "            if params['verbose']:\n",
    "                print(\n",
    "                    \"Plotting timedelay vs. amplitude for the \"\n",
    "                    f\"{i+1}-th (/{len(filtered_dnos)}) SiPM \"\n",
    "                    f\"data - {filtered_dnos[i].get_title()}\"\n",
    "                )\n",
    "        \n",
    "        idx = i%axes_per_canvas\n",
    "        j, k = int(idx//cols_per_canvas), int(idx%cols_per_canvas)\n",
    "        current_fig = figs[int(i//axes_per_canvas)]\n",
    "        current_axes = axes[int(i//axes_per_canvas)][j, k]\n",
    "            \n",
    "        filtered_dnos[i].plot_timedelay_vs_amplitude(   \n",
    "            current_axes,\n",
    "            mode='hist2d', \n",
    "            nbins=150,\n",
    "            axes_title=darknoisemeas_objects[i].get_title(abbreviate=True),\n",
    "            plot_half_a_pe_level=True,\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            WaveformSet.set_custom_labels_visibility(current_axes, j, k, rows_per_canvas)\n",
    "        except AttributeError:\n",
    "            continue\n",
    "        \n",
    "        # Are you getting a TypeError from scipy.optimize.curve_fit? \n",
    "        # scipy.signal.find_peaks() might be detecting mini-peaks \n",
    "        # which are made up of just one or two samples. In this case, \n",
    "        # fitting a 3-parameters gaussian to 1 or 2 samples is \n",
    "        # not (mathematically) well constrained. To filter out these\n",
    "        # mini-peaks, tune up minimal_prominence_wrt_max.\n",
    "\n",
    "\n",
    "    for i in range(canvases_no):\n",
    "        \n",
    "        if params['verbose']:\n",
    "            print(\n",
    "                \"Reporting the levels-computation results \"\n",
    "                f\"for the [{(i * axes_per_canvas) + 1}-\"\n",
    "                f\"{(i+1)*axes_per_canvas}] (/{len(filtered_dnos)}) \"\n",
    "                \"SiPM data\"\n",
    "            )\n",
    "\n",
    "        # Two plots per page\n",
    "        if i%2 == 0:\n",
    "\n",
    "            # If this is the first plot we are adding\n",
    "            # to this page, then add the title and the\n",
    "            # first plot\n",
    "            report_pdf.add_text(\n",
    "                f\"0.5- and 1.5-PE computation results\",\n",
    "                horizontal_pos_frac=None,\n",
    "                vertical_pos_frac=0.95,\n",
    "                max_width_frac=0.9,\n",
    "                font_size=params['title_font_size'],\n",
    "                horizontally_center=True\n",
    "            )\n",
    "\n",
    "            figs[i].tight_layout()\n",
    "            report_pdf.add_plot(\n",
    "                figs[i],\n",
    "                horizontal_pos_frac=None,\n",
    "                vertical_pos_frac=0.35,\n",
    "                plot_width_wrt_page_width=0.8,\n",
    "                horizontally_center=True\n",
    "            )\n",
    "\n",
    "            # If it's the last plot we are adding,\n",
    "            # even if it's the first one of the page,\n",
    "            # then close the page and start a new one\n",
    "            # for plots of other sections\n",
    "            if i == canvases_no-1:\n",
    "                report_pdf.close_page_and_start_a_new_one() \n",
    "\n",
    "        else: # i%2 == 1\n",
    "\n",
    "            # If it's the second plot we are adding\n",
    "            # to this page, then put it below the\n",
    "            # first one and go to a new page\n",
    "            figs[i].tight_layout()\n",
    "            report_pdf.add_plot(\n",
    "                figs[i],\n",
    "                horizontal_pos_frac=None,\n",
    "                vertical_pos_frac=0.0,\n",
    "                plot_width_wrt_page_width=0.8,\n",
    "                horizontally_center=True\n",
    "            )\n",
    "\n",
    "            started_a_new_pdf, aux = PDFGenerator.smart_close_page(\n",
    "                report_pdf,\n",
    "                params['max_pages_per_pdf_chunk'],\n",
    "                pdf_chunks_filepaths_generator\n",
    "            )\n",
    "\n",
    "            if started_a_new_pdf:\n",
    "                del report_pdf\n",
    "                report_pdf = aux\n",
    "                pdf_reports_filepaths.append(report_pdf.OutputFilepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Compute DCR, XTP and APP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_DCR = []\n",
    "i_XTP = []\n",
    "i_APP = []\n",
    "\n",
    "for i in range(len(filtered_dnos)):\n",
    "\n",
    "    if analysis_reliability[i] < 2:\n",
    "        if params['verbose']:\n",
    "            print(\n",
    "                \"Skipping the DCR, XTP and APP computation \"\n",
    "                f\"for the {i+1}-th (/{len(filtered_dnos)}) \"\n",
    "                f\"(0/1-reliable) SiPM data - {filtered_dnos[i].get_title()}\"\n",
    "            )\n",
    "        continue\n",
    "    else:\n",
    "        if params['verbose']:\n",
    "            print(\n",
    "                \"Computing the DCR, XTP and APP for the \"\n",
    "                f\"{i+1}-th (/{len(filtered_dnos)}) SiPM \"\n",
    "                f\"data - {filtered_dnos[i].get_title()}\"\n",
    "            )\n",
    "\n",
    "    i_DCR.append((\n",
    "        i, \n",
    "        filtered_dnos[i].get_dark_count_rate_in_mHz_per_mm2(    # May throw a TypeError, characterize it\n",
    "            params['sipm_sensitive_surface_area_in_mm2']\n",
    "        )\n",
    "    ))\n",
    "\n",
    "    i_XTP.append((\n",
    "        i,\n",
    "        filtered_dnos[i].get_cross_talk_probability()   # May throw a cuex.NoAvailableData, characterize it\n",
    "    ))\n",
    "\n",
    "    i_APP.append((\n",
    "        i,\n",
    "        filtered_dnos[i].get_after_pulse_probability()  # May throw a TypeError, characterize it\n",
    "    ))\n",
    "\n",
    "DCR = [i_DCR[i][1] for i in range(len(i_DCR))]\n",
    "XTP = [i_XTP[i][1] for i in range(len(i_XTP))]\n",
    "APP = [i_APP[i][1] for i in range(len(i_APP))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Purge from bursts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purged_darknoisemeas_objects = []\n",
    "for i in range(len(darknoisemeas_objects)):\n",
    "    # Note that, in order to compute the purged DN objects,\n",
    "    # what we are purging is the already-filtered objects\n",
    "    # Also note that, by construction of filtered_dnos \n",
    "    # (some cells above), the purged version of \n",
    "    # darknoisemeas_objects[i] is purged_darknoisemeas_objects[i]\n",
    "\n",
    "    if analysis_reliability[i] < 2:\n",
    "        if params['verbose']:\n",
    "            print(\n",
    "                f\"Skipping the purging of the {i+1}-th \"\n",
    "                f\"(/{len(filtered_dnos)}) (0/1-reliable) \"\n",
    "                f\"SiPM data - {filtered_dnos[i].get_title()}\"\n",
    "            )\n",
    "\n",
    "        # Add a None entry for the sake of preserving\n",
    "        # the ordering of the darknoisemeas_objects\n",
    "        purged_darknoisemeas_objects.append(None)\n",
    "\n",
    "    else:\n",
    "        if params['verbose']:\n",
    "            print(\n",
    "                f\"Purging from bursts the {i+1}-th \"\n",
    "                f\"(/{len(filtered_dnos)}) SiPM data \"\n",
    "                f\"- {filtered_dnos[idx].get_title()}\"\n",
    "            )\n",
    "\n",
    "        purged_darknoisemeas_objects.append(\n",
    "            DarkNoiseMeas.purge_bursts(\n",
    "                filtered_dnos[i],\n",
    "                min_events_no=params['min_consecutive_peaks_for_burst'],\n",
    "                timedelay_threshold_in_s=params['max_timedelay_for_consecutive_peak_in_s']\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if len(purged_darknoisemeas_objects[-1].Waveforms) < params['minimum_number_of_non_burst_waveforms']:\n",
    "\n",
    "            analysis_reliability[i] = 2\n",
    "\n",
    "            if params['verbose']:\n",
    "                print(f\"WARNING: Only {len(purged_darknoisemeas_objects[-1].Waveforms)} \"\n",
    "                      f\"waveforms (< {params['minimum_number_of_non_burst_waveforms']}) \"\n",
    "                      f\"were left after purging the busts. The analysis for this \"\n",
    "                      \"SiPM has been tagged as 2-reliable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Generate output dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = None\n",
    "fIsFirst = True\n",
    "\n",
    "# Iterating over filtered_dnos\n",
    "for i in range(len(filtered_dnos)):\n",
    "\n",
    "    aux = filtered_dnos[i].output_summary(        \n",
    "        params['sipm_sensitive_surface_area_in_mm2'],\n",
    "        additional_entries= {\n",
    "            \"merged_points\": params['merged_points'],\n",
    "            \"sipm_sensitive_surface_area_in_mm2\": params['sipm_sensitive_surface_area_in_mm2'],\n",
    "            \"signal_fraction_for_median_cutoff\": params['signal_fraction_for_median_cutoff'],\n",
    "            \"minimal_height_wrt_baseline_in_AU\": params['minimal_height_wrt_baseline_in_AU'],\n",
    "            \"minimum_peaks_prominence\": params['minimum_peaks_prominence'],\n",
    "            \"minimum_peak_width_in_s\": params['minimum_peak_width_in_s'],\n",
    "            \"rel_height_for_peak_width\": params['rel_height_for_peak_width'],\n",
    "            \"starting_fraction\": params['starting_fraction'],\n",
    "            \"step_fraction\": params['step_fraction'],\n",
    "            \"minimal_prominence_wrt_max\": params['minimal_prominence_wrt_max'],\n",
    "            \"gaussian_fit_std_no\": params['gaussian_fit_std_no'],\n",
    "            \"amplitudes_histogram_bins_no\": params['amplitudes_histogram_bins_no'],\n",
    "            \"timedelay_cut\": params['timedelay_cut'],\n",
    "            \"minimum_integral\": params['minimum_integral'],\n",
    "            \"integral_window_width_s\": params['integral_window_width_s'],\n",
    "            \"min_consecutive_peaks_for_burst\": params['min_consecutive_peaks_for_burst'],\n",
    "            \"max_timedelay_for_consecutive_peak_in_s\": params['max_timedelay_for_consecutive_peak_in_s'],\n",
    "            \"burstless_DC#\": purged_darknoisemeas_objects[i].get_dark_counts_number()\n",
    "            if analysis_reliability[i] > 2 else float('nan'),\n",
    "            \"burstless_DCR_mHz_per_mm2\": purged_darknoisemeas_objects[i].get_dark_count_rate_in_mHz_per_mm2(\n",
    "                params['sipm_sensitive_surface_area_in_mm2']\n",
    "            ) if analysis_reliability[i] > 2 else float('nan'),\n",
    "            \"burstless_XTP\": purged_darknoisemeas_objects[i].get_cross_talk_probability()\n",
    "            if analysis_reliability[i] > 2 else float('nan'),\n",
    "            \"burstless_APP\": purged_darknoisemeas_objects[i].get_after_pulse_probability()\n",
    "            if analysis_reliability[i] > 2 else float('nan'),\n",
    "            \"is_filtered\": True,\n",
    "            \"filter_type\": 'integral',\n",
    "            \"analysis_reliability\": analysis_reliability[i]\n",
    "        },\n",
    "        folderpath=None,\n",
    "        include_analysis_results=True if analysis_reliability[i] > 1 else False,\n",
    "        overwrite=params['json_overwrite'],\n",
    "        indent=params['indent'],\n",
    "        verbose=params['verbose'])\n",
    "    \n",
    "    if fIsFirst:\n",
    "        # Convert the model data to a dictionary of lists\n",
    "        data = {key: [value] for key, value in aux.items()}\n",
    "        fIsFirst = False\n",
    "    else:\n",
    "        for key in data.keys():\n",
    "            data[key].append(aux[key])\n",
    "\n",
    "output_dataframe = pd.DataFrame(data)\n",
    "\n",
    "if params['verbose']:\n",
    "    print(\n",
    "        f\"Saving the output dataframe to \"\n",
    "        f\"{os.path.abspath(summary_dir)}/{params['output_dataframe_filename']}\"\n",
    "    )\n",
    "\n",
    "output_dataframe.to_csv(\n",
    "    os.path.join(\n",
    "        summary_dir,\n",
    "        params['output_dataframe_filename']+'.csv'\n",
    "    )\n",
    ")\n",
    "\n",
    "output_dataframe.to_pickle(\n",
    "    os.path.join(\n",
    "        summary_dir,\n",
    "        params['output_dataframe_filename']+'.pkl'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Report the DCR, XTP and APP resulting distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_to_show = [\n",
    "    'DCR_mHz_per_mm2',\n",
    "    'XTP',\n",
    "    'APP'\n",
    "]\n",
    "table_ndigits = {\n",
    "    'DCR_mHz_per_mm2': 3,\n",
    "    'XTP': 2,\n",
    "    'APP': 2\n",
    "}\n",
    "\n",
    "# For mean and std computation\n",
    "samples_wo_outliers = {\n",
    "    'DCR_mHz_per_mm2': np.array([\n",
    "        sample for sample in DCR \n",
    "        if sample <= tools.thresholds['DCR_mHz_per_mm2']['threshold']]),\n",
    "    'XTP': np.array([\n",
    "        sample for sample in XTP \n",
    "        if sample <= tools.thresholds['XTP']['threshold']]),\n",
    "    'APP': np.array([\n",
    "        sample for sample in APP \n",
    "        if sample <= tools.thresholds['APP']['threshold']])\n",
    "}\n",
    "red_lightness = 0.7\n",
    "colour_decide = {\n",
    "    'DCR_mHz_per_mm2': lambda val : (0.8, 0.8, 0.) if math.isnan(val)\n",
    "    else (\n",
    "        (1., 0., 0.)\n",
    "        if val > tools.thresholds['DCR_mHz_per_mm2']['threshold']\n",
    "        else ((1.,red_lightness,red_lightness) if val > tools.thresholds['DCR_mHz_per_mm2']['pre_threshold']\n",
    "        else 'white')\n",
    "    ),\n",
    "    'XTP': lambda val : (0.8, 0.8, 0.) if math.isnan(val)\n",
    "    else (\n",
    "        (1., 0., 0.)\n",
    "        if val > tools.thresholds['XTP']['threshold']\n",
    "        else ((1.,red_lightness,red_lightness) if val > tools.thresholds['XTP']['pre_threshold']\n",
    "        else 'white')\n",
    "    ),\n",
    "\n",
    "    'APP': lambda val : (0.8, 0.8, 0.) if math.isnan(val)\n",
    "    else (\n",
    "        (1., 0., 0.)\n",
    "        if val > tools.thresholds['APP']['threshold']\n",
    "        else ((1.,red_lightness,red_lightness) if val > tools.thresholds['APP']['pre_threshold']\n",
    "        else 'white')\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params['generate_report']:\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        ncols=3,\n",
    "        figsize=(15, 5)\n",
    "    )\n",
    "\n",
    "    tools.plot_histogram(\n",
    "        axes[0],\n",
    "        np.array(DCR),\n",
    "        bins=params['resulting_distributions_nbins'],\n",
    "        hist_range=(0., 2.*tools.thresholds['DCR_mHz_per_mm2']['threshold']),\n",
    "        xlabel=r'DCR (mHz/mm$^2$)',\n",
    "        ylabel='Hits', \n",
    "        figtitle=r\"$\\overline{\\text{DCR}}=$\"+f\"{np.round(np.mean(samples_wo_outliers['DCR_mHz_per_mm2']), decimals=2)}, \"+\n",
    "        r\"$\\text{STD}=$\"+f\"{np.round(np.std(samples_wo_outliers['DCR_mHz_per_mm2']), decimals=2)}\",\n",
    "        fontsize=params['text_font_size'],\n",
    "        yticks_step=1\n",
    "    )\n",
    "    axes[0].axvline(\n",
    "        x=tools.thresholds['DCR_mHz_per_mm2']['threshold'],\n",
    "        color=(1.0, 0.0, 0.0),\n",
    "        linestyle='-',\n",
    "        linewidth=params['vertical_thresholds_linewidth']\n",
    "    )\n",
    "    axes[0].axvline(\n",
    "        x=tools.thresholds['DCR_mHz_per_mm2']['pre_threshold'],\n",
    "        color=(1.0, red_lightness, red_lightness),\n",
    "        linestyle='--',\n",
    "        linewidth=params['vertical_thresholds_linewidth']\n",
    "    )\n",
    "    tools.plot_histogram( \n",
    "        axes[1],\n",
    "        np.array(XTP),\n",
    "        bins=params['resulting_distributions_nbins'],\n",
    "        hist_range=(0., 2.*tools.thresholds['XTP']['threshold']),\n",
    "        xlabel='X-Talk probability',\n",
    "        ylabel='Hits', \n",
    "        figtitle=r\"$\\overline{\\text{XTP}}=$\"+f\"{np.round(np.mean(samples_wo_outliers['XTP']), decimals=3)}, \"+\n",
    "        r\"$\\text{STD}=$\"+f\"{np.round(np.std(samples_wo_outliers['XTP']), decimals=3)}\",\n",
    "        fontsize=params['text_font_size'],\n",
    "        yticks_step=1\n",
    "    )\n",
    "    axes[1].axvline(\n",
    "        x=tools.thresholds['XTP']['threshold'],\n",
    "        color=(1.0, 0.0, 0.0),\n",
    "        linestyle='-',\n",
    "        linewidth=params['vertical_thresholds_linewidth']\n",
    "    )\n",
    "    axes[1].axvline(\n",
    "        x=tools.thresholds['XTP']['pre_threshold'],\n",
    "        color=(1.0, red_lightness, red_lightness),\n",
    "        linestyle='--',\n",
    "        linewidth=params['vertical_thresholds_linewidth']\n",
    "    )\n",
    "    tools.plot_histogram(\n",
    "        axes[2],\n",
    "        np.array(APP),\n",
    "        bins=params['resulting_distributions_nbins'],\n",
    "        hist_range=(0., 2.*tools.thresholds['APP']['threshold']),\n",
    "        xlabel='After pulse probability',\n",
    "        ylabel='Hits', \n",
    "        figtitle=r\"$\\overline{\\text{APP}}=$\"+f\"{np.round(np.mean(samples_wo_outliers['APP']), decimals=3)}, \"+\n",
    "        r\"$\\text{STD}=$\"+f\"{np.round(np.std(samples_wo_outliers['APP']), decimals=3)}\",\n",
    "        fontsize=params['text_font_size'],\n",
    "        yticks_step=1\n",
    "    )\n",
    "    axes[2].axvline(\n",
    "        x=tools.thresholds['APP']['threshold'],\n",
    "        color=(1.0, 0.0, 0.0),\n",
    "        linestyle='-',\n",
    "        linewidth=params['vertical_thresholds_linewidth']\n",
    "    )\n",
    "    axes[2].axvline(\n",
    "        x=tools.thresholds['APP']['pre_threshold'],\n",
    "        color=(1.0, red_lightness, red_lightness),\n",
    "        linestyle='--',\n",
    "        linewidth=params['vertical_thresholds_linewidth']\n",
    "    )\n",
    "\n",
    "    if params['verbose']:\n",
    "        print(\n",
    "            \"Reporting the DCR, XTP and APP \"\n",
    "            \"distributions including all of the SiPMs\"\n",
    "        )\n",
    "\n",
    "    report_pdf.add_text(\n",
    "        f\"DCR, XTP and APP resulting distributions\",\n",
    "        horizontal_pos_frac=None,\n",
    "        vertical_pos_frac=0.95,\n",
    "        max_width_frac=0.9,\n",
    "        font_size=params['title_font_size'],\n",
    "        horizontally_center=True\n",
    "    )\n",
    "\n",
    "    fig.tight_layout()\n",
    "    report_pdf.add_plot(\n",
    "        fig,\n",
    "        horizontal_pos_frac=None,\n",
    "        vertical_pos_frac=0.45,\n",
    "        plot_width_wrt_page_width=0.99,\n",
    "        horizontally_center=True\n",
    "    )\n",
    "\n",
    "    # Don't close the last page nor save the PDF\n",
    "    # yet, because we will place some tables in it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. Report the DCR, XTP and APP result-tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_vertical_pos_frac = {\n",
    "    'DCR_mHz_per_mm2': 0.3,\n",
    "    'XTP': 0.2,\n",
    "    'APP': 0.1\n",
    "}\n",
    "\n",
    "if params['generate_report']:\n",
    "    \n",
    "    for variable in field_to_show:\n",
    "\n",
    "        table = tools.strip_ID_vs_sipm_location_dataframe(\n",
    "            output_dataframe, \n",
    "            variable, \n",
    "            significant_figures=table_ndigits[variable]\n",
    "        )\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(15, 2))\n",
    "        ax.axis('off')\n",
    "        ax.table(\n",
    "            cellText=table.values, \n",
    "            colLabels=table.columns, \n",
    "            rowLabels=[' '+str(aux)+' ' for aux in range(1,7)], \n",
    "            colWidths = [0.06 for _ in table.columns],\n",
    "            cellColours = [\n",
    "                [\n",
    "                    colour_decide[variable](\n",
    "                        float(val)\n",
    "                    ) for val in row\n",
    "                ] for row in table.values\n",
    "            ],\n",
    "            cellLoc = 'center',\n",
    "            loc='center'\n",
    "        )\n",
    "        ax.set_title(variable)\n",
    "        \n",
    "        report_pdf.add_plot(\n",
    "            fig,\n",
    "            horizontal_pos_frac=None,\n",
    "            vertical_pos_frac=tables_vertical_pos_frac[variable],\n",
    "            plot_width_wrt_page_width=0.99,\n",
    "            horizontally_center=True\n",
    "        )\n",
    "\n",
    "    report_pdf.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14. Generate the cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params['generate_report']:\n",
    "\n",
    "    path_to_cover_pdf = os.path.join(\n",
    "        summary_dir,\n",
    "        'temp_cover.pdf'\n",
    "    )\n",
    "\n",
    "    cover_pdf = PDFGenerator(path_to_cover_pdf)\n",
    "\n",
    "    cover_pdf.add_text(\n",
    "        f\"Darknoise analysis report\",\n",
    "        horizontal_pos_frac=None,\n",
    "        vertical_pos_frac=0.95,\n",
    "        max_width_frac=0.9,\n",
    "        font_size=params['title_font_size'],\n",
    "        horizontally_center=True\n",
    "    )\n",
    "\n",
    "    clustered_boards_string = tools.get_string_of_contiguously_clustered_integers(\n",
    "        tools.cluster_integers_by_contiguity(list(output_dataframe.groupby('strip_ID').groups.keys()))\n",
    "    )\n",
    "\n",
    "    cover_pdf.add_text(\n",
    "        f\"Analyzed boards: {clustered_boards_string}\",\n",
    "        horizontal_pos_frac=None,\n",
    "        vertical_pos_frac=0.90,\n",
    "        max_width_frac=0.9,\n",
    "        font_size=params['subtitle_font_size'],\n",
    "        horizontally_center=True\n",
    "    )\n",
    "\n",
    "    cover_pdf.add_text(\n",
    "        f\"The results have been dumped to both, a CSV file \"\n",
    "        f\"('{params['output_dataframe_filename']}.csv') and a pickle file \"\n",
    "        f\"('{params['output_dataframe_filename']}.pkl'), saved alongside this\"\n",
    "        \" report.\", \n",
    "        horizontal_pos_frac=None,\n",
    "        vertical_pos_frac=0.80,\n",
    "        max_width_frac=0.9,\n",
    "        font_size=params['text_font_size'],\n",
    "        horizontally_center=True\n",
    "    )\n",
    "\n",
    "    # n_reliable_analyses[i] gives the number of SiPMs\n",
    "    # with analysis_reliability[i] equal to n, where\n",
    "    # n = 0, 1, 2\n",
    "    n_reliable_analyses = {\n",
    "        i: np.count_nonzero(np.array(analysis_reliability) == i)\n",
    "        for i in range(3)\n",
    "    }\n",
    "\n",
    "    if sum(list(n_reliable_analyses.values())) == 0:\n",
    "        cover_pdf.add_text(\n",
    "            f\"All of the analyses have been tagged as reliable\",\n",
    "            horizontal_pos_frac=None,\n",
    "            vertical_pos_frac=0.71,\n",
    "            max_width_frac=0.9,\n",
    "            font_size=params['text_font_size'],\n",
    "            font_color=colors.green,\n",
    "            horizontally_center=True\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        cover_pdf.add_text(\n",
    "            f\"A total of {n_reliable_analyses[0]} (resp. \"\n",
    "            f\"{n_reliable_analyses[1]}, {n_reliable_analyses[2]}) \"\n",
    "            f\"analyses, out of {len(darknoisemeas_objects)} - the \"\n",
    "            f\"{round(100.*n_reliable_analyses[0]/len(darknoisemeas_objects), ndigits=2)} % \"\n",
    "            f\"(resp. {round(100.*n_reliable_analyses[1]/len(darknoisemeas_objects), ndigits=2)} %, \"\n",
    "            f\"{round(100.*n_reliable_analyses[2]/len(darknoisemeas_objects), ndigits=2)} %) - \"\n",
    "            \"have been tagged as 0- (resp. 1-, 2-) reliable:\",\n",
    "            horizontal_pos_frac=None,\n",
    "            vertical_pos_frac=0.71,\n",
    "            max_width_frac=0.9,\n",
    "            font_size=params['text_font_size'],\n",
    "            font_color=colors.red,\n",
    "            horizontally_center=True\n",
    "        )\n",
    "\n",
    "        added_lines_so_far = tools.natural_numbers_generator()\n",
    "        added_lines_so_far_in_this_page = 0\n",
    "        fNewPage = False\n",
    "        aux_starting_vertical_pos_frac = {\n",
    "            True: 0.9, False: 0.67\n",
    "        }\n",
    "\n",
    "        for i in range(len(analysis_reliability)):\n",
    "            if analysis_reliability[i] < 3:\n",
    "                vertical_pos_frac = \\\n",
    "                    aux_starting_vertical_pos_frac[fNewPage] \\\n",
    "                        - (0.02 * (added_lines_so_far_in_this_page))\n",
    "\n",
    "                if vertical_pos_frac < 0.1:\n",
    "                    # Most of the times, the cover PDF will encompass\n",
    "                    # just one page. For very ill-formed cases, it can\n",
    "                    # go up to some pages (less than 10). That's why\n",
    "                    # I am not using the smart-close-page method here.\n",
    "                    cover_pdf.close_page_and_start_a_new_one()\n",
    "                    fNewPage = True\n",
    "\n",
    "                    added_lines_so_far_in_this_page = 0\n",
    "                    vertical_pos_frac = \\\n",
    "                        aux_starting_vertical_pos_frac[fNewPage]\n",
    "\n",
    "                cover_pdf.add_text(\n",
    "                    f\"{next(added_lines_so_far)}) {darknoisemeas_objects[i].get_title()}\",\n",
    "                    horizontal_pos_frac=None,\n",
    "                    vertical_pos_frac=vertical_pos_frac,\n",
    "                    max_width_frac=0.9,\n",
    "                    font_size=params['text_font_size']-4.,\n",
    "                    font_color={\n",
    "                        0: colors.red,\n",
    "                        1: colors.orange,\n",
    "                        2: colors.blue\n",
    "                    }[analysis_reliability[i]],\n",
    "                    horizontally_center=True\n",
    "                )\n",
    "                \n",
    "                added_lines_so_far_in_this_page += 1\n",
    "\n",
    "    cover_pdf.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15. Join the PDF chunks and add the cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params['generate_report']:\n",
    "\n",
    "    aux_path_to_report_pdf = os.path.join(\n",
    "        summary_dir,\n",
    "        params['report_output_filename']\n",
    "    )\n",
    "\n",
    "    if params['verbose']:\n",
    "        print(\n",
    "            f\"Saving the report PDF to \"\n",
    "            f\"{os.path.abspath(aux_path_to_report_pdf)}\"\n",
    "        )\n",
    "\n",
    "    PDFGenerator.concatenate_PDFs(\n",
    "        pdf_reports_filepaths,\n",
    "        aux_path_to_report_pdf\n",
    "    )\n",
    "\n",
    "    PDFGenerator.add_cover(\n",
    "        path_to_cover_pdf,\n",
    "        aux_path_to_report_pdf,\n",
    "        # Overwritting the report PDF with the\n",
    "        # one which already includes the cover\n",
    "        aux_path_to_report_pdf,\n",
    "    )\n",
    "\n",
    "    os.remove(path_to_cover_pdf)    \n",
    "    for filepath in pdf_reports_filepaths:\n",
    "        os.remove(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging / Trash can"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oscillatority analysis\n",
    "from scipy import interpolate as spinter\n",
    "\n",
    "def oscillatority(x, y, period):\n",
    "\n",
    "    \"\"\"\n",
    "    - x (unidimensional numpy array)\n",
    "    - y (unidimensional numpy array): x.shape must match y.shape\n",
    "    - period (scalar float)\n",
    "    \"\"\"\n",
    "\n",
    "    # Implementing oscillatority as given by\n",
    "    # (\\int _{t_0}^{t_0+\\Delta t} (f(t)-mean_f)*(f(t+period)-mean_f) dt)/\\Delta t\n",
    "\n",
    "    # Determine actual interval of integration,\n",
    "    # which is [x[0], x[-1]-period]\n",
    "\n",
    "\n",
    "    f = spinter.CubicSpline(x, y)\n",
    "    average_f = np.mean(y)\n",
    "\n",
    "    mask = (x <= (x[-1]-period))\n",
    "    reduced_x = x[mask]\n",
    "    reduced_y = y[mask]\n",
    "\n",
    "    integration_width = (x[-1]-period)-x[0]\n",
    "\n",
    "    integrand = np.vectorize(lambda input : ((f(input)-average_f)*(f(input+period)-average_f))/integration_width)\n",
    "    integrand = integrand(reduced_x)\n",
    "\n",
    "    # Normalized by the square amplitude of the signal\n",
    "    return np.trapz(integrand, x=reduced_x)/((np.max(y)-np.min(x))*(np.max(y)-np.min(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# darknoisemeas_objects[i].Waveforms.plot(\n",
    "#     wvfs_to_plot=18, \n",
    "#     plot_peaks=False,\n",
    "#     #ylim=(0.00, 0.18),\n",
    "#     #ylim=(0.03,0.09),\n",
    "#     wvf_linewidth=0.2,\n",
    "#     x0=[],\n",
    "#     y0=[],\n",
    "#     randomize=True,\n",
    "#     fig_title=f\"Iterator {i}, {darknoisemeas_objects[i].get_title()}\",\n",
    "#     mode='grid',\n",
    "#     nrows=3, ncols=3\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "massibo_ana_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
