{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import textwrap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tools as tools\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats as spstats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load the input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write here the ABSOLUTE path to the input parameters file\n",
    "input_parameters_filepath = ''\n",
    "\n",
    "with open(\n",
    "        input_parameters_filepath,\n",
    "        \"r\",\n",
    "        encoding=\"utf-8\"\n",
    "    ) as file:\n",
    "        \n",
    "        params = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Read the dataframes and combine into a single one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataframes\n",
    "dataframes = []\n",
    "for filename in os.listdir(params['input_dir']):\n",
    "    if filename.endswith('.pkl'):\n",
    "        filepath = os.path.join(\n",
    "            params['input_dir'],\n",
    "            filename\n",
    "        )\n",
    "        df = pd.read_pickle(filepath)\n",
    "        dataframes.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that every DataFrame has the same number of columns\n",
    "aux = [len(df.columns) for df in dataframes]\n",
    "for i in range(1, len(aux)):\n",
    "    if aux[i-1]!=aux[i]:\n",
    "        raise Exception(\n",
    "            f\"DataFrames {i-1} and {i} have different number of columns\"\n",
    "        )\n",
    "print(\n",
    "    f\"All DataFrames have {aux[0]} columns\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the name of the columns match DataFrame-wise\n",
    "for i in range(len(dataframes[0].columns)):\n",
    "    for j in range(1, len(dataframes)):\n",
    "        if dataframes[0].columns[i] != dataframes[j].columns[i]:\n",
    "            raise Exception(\n",
    "                f\"The name of the column {i} of DataFrame 0 \"\n",
    "                f\"({dataframes[0].columns[i]}) does not match \"\n",
    "                f\"column {i} of DataFrame {j} \"\n",
    "                f\"({dataframes[j].columns[i]})\"\n",
    "            )\n",
    "print(\n",
    "    \"All DataFrames have the same column names\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all dataframes into a single dataframe\n",
    "dataframe = pd.concat(\n",
    "    dataframes, \n",
    "    ignore_index=True\n",
    ")\n",
    "print(\n",
    "    f\"Combined DataFrame has {len(dataframe)} rows\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Delete ignored columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in params['columns_to_ignore']:\n",
    "    if column in dataframe.columns:\n",
    "        dataframe = dataframe.drop(\n",
    "            column,\n",
    "            axis=1\n",
    "        )\n",
    "print(\n",
    "    f\"The resulting dataframe has {len(dataframe.columns)} columns\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Choose which boards should be analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params['visualize_all_boards']:\n",
    "    filtered_df = dataframe\n",
    "else:\n",
    "    boards_to_visualize = []\n",
    "    for set_no in params['sets_to_analyze']:\n",
    "        boards_to_visualize += tools.strip_ids_of_set[set_no]\n",
    "\n",
    "    disyuntive_filters = []\n",
    "    for strip_ID in boards_to_visualize:\n",
    "        disyuntive_filters.append(\n",
    "            dataframe['strip_ID'] == int(strip_ID)\n",
    "        )\n",
    "\n",
    "    filter = disyuntive_filters[0]\n",
    "    for i in range(1,len(disyuntive_filters)):\n",
    "        filter |= disyuntive_filters[i]     # Logical 'OR'\n",
    "\n",
    "    filtered_df = dataframe[filter]\n",
    "    filtered_df = filtered_df.reset_index(drop=True)\n",
    "\n",
    "print(\n",
    "    f\"Filtered DataFrame has {len(filtered_df)} rows\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Apply more filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement more filters? Define them here\n",
    "conjuntive_filters = []\n",
    "conjuntive_filters.append(\n",
    "    filtered_df['analysis_reliability']>1\n",
    ")\n",
    "\n",
    "disyuntive_filters = []\n",
    "\n",
    "disyuntive_filters.append(\n",
    "    filtered_df['overvoltage_V']==2.\n",
    ")\n",
    "disyuntive_filters.append(\n",
    "    filtered_df['overvoltage_V']==3.\n",
    ")\n",
    "disyuntive_filters.append(\n",
    "    filtered_df['overvoltage_V']==4.\n",
    ")\n",
    "\n",
    "# Gain measurements of tray 115 of the re-test batch (i.e. those taken in April) have overvoltages 2.7, 3.0, 3.1 and 4.1\n",
    "\n",
    "# Apply the filters\n",
    "total_filter = pd.Series(\n",
    "    np.ones(len(filtered_df), dtype=bool),\n",
    ")\n",
    "\n",
    "for filter in conjuntive_filters:\n",
    "    total_filter &= filter  # Conjuntive filters\n",
    "\n",
    "if len(disyuntive_filters) == 0:\n",
    "    total_disyuntive_filter = pd.Series(\n",
    "        np.ones(len(filtered_df), dtype=bool)\n",
    "    )\n",
    "else:\n",
    "    total_disyuntive_filter = pd.Series(\n",
    "        np.zeros(len(filtered_df), dtype=bool)\n",
    "    )\n",
    "    for filter in disyuntive_filters:\n",
    "        # Disyuntive filters\n",
    "        total_disyuntive_filter |= filter\n",
    "\n",
    "total_filter &= total_disyuntive_filter\n",
    "filtered_df = filtered_df[list(total_filter)]\n",
    "filtered_df = filtered_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.sort_values(by=['strip_ID', 'sipm_location'], inplace=True)\n",
    "print(\n",
    "    f\"Filtered DataFrame has {len(filtered_df)} rows\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Display the considered boards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_boards_string = \\\n",
    "    tools.get_string_of_contiguously_clustered_integers(\n",
    "        tools.cluster_integers_by_contiguity(\n",
    "            list(filtered_df.groupby('strip_ID').groups.keys())\n",
    "        )\n",
    "    )\n",
    "\n",
    "clustered_boards_string = \\\n",
    "    '\\n'.join(textwrap.wrap(\n",
    "        clustered_boards_string,\n",
    "        width=72\n",
    "    ))\n",
    "\n",
    "print(\n",
    "    f\"Boards in the DataFrame: {clustered_boards_string}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Graph the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_fontsize=10   # Title of plots\n",
    "labels_fontsize=16  # Axes-labels of plots\n",
    "ticks_fontsize=14\n",
    "nbins=30            # Number of bins for 1-D histograms\n",
    "ndigits=2           # Number of digits for means and stds\n",
    "DCR_ndigits=2       # Number of digits for DCRs\n",
    "fit_to_pdf = True\n",
    "distribution = spstats.lognorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1. Graph gain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_nbins = 100\n",
    "infer_range = False\n",
    "# The following range is ignored if infer_range is True\n",
    "gain_histograms_range = (0., 0.4e+7)\n",
    "\n",
    "overvoltage_grouped_dataframes = {key: group for key, group in filtered_df.groupby('overvoltage_V')}\n",
    "gain_characteristics_with_overvoltage = {\n",
    "    key: {\n",
    "        'mean': np.mean(overvoltage_grouped_dataframes[key]['gain_in_#e-']),\n",
    "        'std': np.std(overvoltage_grouped_dataframes[key]['gain_in_#e-'])\n",
    "    } for key in overvoltage_grouped_dataframes.keys()\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=1,\n",
    "    ncols=1,\n",
    "    figsize=(6, 5)\n",
    ")\n",
    "\n",
    "if infer_range:\n",
    "    aux_min_overvoltage = min(overvoltage_grouped_dataframes.keys())\n",
    "    aux_max_overvoltage = max(overvoltage_grouped_dataframes.keys())\n",
    "    gain_histograms_range = (\n",
    "        gain_characteristics_with_overvoltage[aux_min_overvoltage]['mean'] \\\n",
    "            - (20. * gain_characteristics_with_overvoltage[aux_min_overvoltage]['std']),\n",
    "        gain_characteristics_with_overvoltage[aux_max_overvoltage]['mean'] \\\n",
    "            + (20. * gain_characteristics_with_overvoltage[aux_max_overvoltage]['std'])\n",
    "    )\n",
    "\n",
    "\n",
    "tools.plot_histogram(\n",
    "    axes,\n",
    "    *[\n",
    "        np.array(overvoltage_grouped_dataframes[overvoltage]['gain_in_#e-'])\n",
    "        for overvoltage in overvoltage_grouped_dataframes.keys()\n",
    "    ],\n",
    "    bins=gain_nbins,\n",
    "    hist_range=gain_histograms_range,\n",
    "    density=False,\n",
    "    xlabel='Gain (#e-)',\n",
    "    ylabel='Hits',\n",
    "    legend_labels=[\n",
    "        f\"OV = {overvoltage} V, \"\n",
    "        r\"$\\mu = $\"\n",
    "        f\"{tools.scientific_notation_str(gain_characteristics_with_overvoltage[overvoltage]['mean'], ndigits=2)}, \"\n",
    "        r\"$\\sigma = $\"\n",
    "        f\"{tools.scientific_notation_str(gain_characteristics_with_overvoltage[overvoltage]['std'], ndigits=2)}, \"\n",
    "        for overvoltage in overvoltage_grouped_dataframes.keys()\n",
    "    ],\n",
    "    linewidth = 1.,\n",
    "    # figtitle=f\"Overvoltage-wise gain distributions - Boards {clustered_boards_string}\",\n",
    "    figtitle=f\"Overvoltage-wise gain distributions - Sets: {params['sets_to_analyze']}\",\n",
    "    fontsize=14,\n",
    "    colourful=True,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2. Graph dark-noise data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.1. DCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCR_bin_width = 5\n",
    "DCR_mean = np.mean(filtered_df['DCR_mHz_per_mm2'])\n",
    "DCR_std = np.std(filtered_df['DCR_mHz_per_mm2'], ddof=1)\n",
    "DCR_outlier_threshold = tools.thresholds['DCR_mHz_per_mm2']['threshold']\n",
    "\n",
    "hist, edges, _ = plt.hist(\n",
    "    filtered_df['DCR_mHz_per_mm2'], \n",
    "    label='w/ bursts',\n",
    "    bins=np.arange(\n",
    "        np.min(filtered_df['DCR_mHz_per_mm2'])-DCR_bin_width, \n",
    "        np.max(filtered_df['DCR_mHz_per_mm2'])+DCR_bin_width,\n",
    "        step=DCR_bin_width),\n",
    "    density=fit_to_pdf,\n",
    "    histtype='step',\n",
    "    color='blue'\n",
    ")\n",
    "\n",
    "if fit_to_pdf:\n",
    "    fit_x = np.linspace(\n",
    "        0,\n",
    "        max(\n",
    "            DCR_outlier_threshold,\n",
    "            np.max(filtered_df['DCR_mHz_per_mm2'])\n",
    "        ),\n",
    "        1000\n",
    "    )\n",
    "    plt.plot(\n",
    "        fit_x,\n",
    "        distribution.pdf(\n",
    "            fit_x,\n",
    "            *distribution.fit(filtered_df['DCR_mHz_per_mm2'])\n",
    "        ),\n",
    "        label=\"Fit to 'w/ bursts'\",\n",
    "        color='blue'\n",
    "    )\n",
    "\n",
    "plt.hist(\n",
    "    filtered_df['burstless_DCR_mHz_per_mm2'], \n",
    "    label='w/o bursts',\n",
    "    bins=np.arange(\n",
    "        np.min(filtered_df['burstless_DCR_mHz_per_mm2'])-DCR_bin_width,\n",
    "        np.max(filtered_df['burstless_DCR_mHz_per_mm2'])+DCR_bin_width,\n",
    "        step=DCR_bin_width),\n",
    "    density=fit_to_pdf,\n",
    "    histtype='step',\n",
    "    color='black'\n",
    ")\n",
    "\n",
    "plt.axvline(\n",
    "    DCR_outlier_threshold,\n",
    "    color='red',\n",
    "    label='Outlier threshold'\n",
    ")\n",
    "plt.xlim(\n",
    "    0,\n",
    "    DCR_outlier_threshold+(0.05*DCR_outlier_threshold)\n",
    ")\n",
    "plt.xlabel(\n",
    "    'DCR (mHz/mm2)',\n",
    "    fontsize=labels_fontsize\n",
    ")\n",
    "plt.ylabel(\n",
    "    'Hits' if not fit_to_pdf else 'Probability density',\n",
    "    fontsize=labels_fontsize\n",
    ")\n",
    "plt.xticks(fontsize=ticks_fontsize)\n",
    "plt.yticks(fontsize=ticks_fontsize)\n",
    "plt.title(\n",
    "    f\"Sets: {params['sets_to_analyze']} \\n w/ bursts - (\"\n",
    "    f\"{round(DCR_mean, ndigits=DCR_ndigits)} +/- {round(DCR_std, ndigits=DCR_ndigits)})\"\n",
    "    f\", w/o bursts - ({round(np.mean(filtered_df['burstless_DCR_mHz_per_mm2']), ndigits=DCR_ndigits)}\"\n",
    "    f\" +/- {round(np.std(filtered_df['burstless_DCR_mHz_per_mm2'], ddof=1), ndigits=DCR_ndigits)})\",\n",
    "    fontsize=title_fontsize)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2. XTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTP_bin_width = 0.01\n",
    "XTP_mean = np.mean(filtered_df['XTP'])\n",
    "XTP_std = np.std(filtered_df['XTP'], ddof=1)\n",
    "XTP_outlier_threshold = tools.thresholds['XTP']['threshold']\n",
    "\n",
    "hist, edges, _ = plt.hist(\n",
    "    filtered_df['XTP'], \n",
    "    label='w/ bursts',\n",
    "    bins=np.arange(\n",
    "        np.min(filtered_df['XTP'])-XTP_bin_width, \n",
    "        np.max(filtered_df['XTP'])+XTP_bin_width,\n",
    "        step=XTP_bin_width),\n",
    "    density=fit_to_pdf,\n",
    "    histtype='step',\n",
    "    color='blue'\n",
    ")\n",
    "\n",
    "if fit_to_pdf:\n",
    "    fit_x = np.linspace(\n",
    "        0,\n",
    "        max(       \n",
    "            XTP_outlier_threshold,\n",
    "            np.max(filtered_df['XTP'])\n",
    "        ),\n",
    "        1000\n",
    "    )\n",
    "    plt.plot(\n",
    "        fit_x,\n",
    "        distribution.pdf(\n",
    "            fit_x,\n",
    "            *distribution.fit(filtered_df['XTP'])\n",
    "        ),\n",
    "        label=\"Fit to 'w/ bursts'\",\n",
    "        color='blue'\n",
    "    )\n",
    "\n",
    "plt.hist(\n",
    "    filtered_df['burstless_XTP'], \n",
    "    label='w/o bursts',\n",
    "    bins=np.arange(\n",
    "        np.min(filtered_df['XTP'])-XTP_bin_width, \n",
    "        np.max(filtered_df['XTP'])+XTP_bin_width,\n",
    "        step=XTP_bin_width),\n",
    "    density=fit_to_pdf,\n",
    "    histtype='step',\n",
    "    color='black'\n",
    ")\n",
    "plt.axvline(\n",
    "    XTP_outlier_threshold,\n",
    "    color='red',\n",
    "    label='Outlier threshold'\n",
    ")\n",
    "plt.xlim(\n",
    "    0,\n",
    "    XTP_outlier_threshold+(0.05*XTP_outlier_threshold)\n",
    ")\n",
    "plt.xlabel(\n",
    "    'X-Talk probability',\n",
    "    fontsize=labels_fontsize\n",
    ")\n",
    "plt.ylabel(\n",
    "    'Hits' if not fit_to_pdf else 'Probability density',\n",
    "    fontsize=labels_fontsize\n",
    ")\n",
    "plt.xticks(fontsize=ticks_fontsize)\n",
    "plt.yticks(fontsize=ticks_fontsize)\n",
    "plt.title(\n",
    "    f\"Sets: {params['sets_to_analyze']} \\n w/ bursts - (\"\n",
    "    f\"{round(XTP_mean, ndigits=ndigits)} +/- {round(XTP_std, ndigits=ndigits)})\"\n",
    "    f\", w/o bursts - ({round(np.mean(filtered_df['burstless_XTP']), ndigits=ndigits)}\"\n",
    "    f\" +/- {round(np.std(filtered_df['burstless_XTP'], ddof=1), ndigits=ndigits)})\",\n",
    "    fontsize=title_fontsize)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3. APP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "APP_bin_width = 0.0035\n",
    "APP_mean = np.mean(filtered_df['APP'])\n",
    "APP_std = np.std(filtered_df['APP'], ddof=1)\n",
    "APP_outlier_threshold = tools.thresholds['APP']['threshold']\n",
    "\n",
    "hist, edges, _ = plt.hist(\n",
    "    filtered_df['APP'], \n",
    "    label='w/ bursts',\n",
    "    bins=np.arange(\n",
    "        np.min(filtered_df['APP'])-APP_bin_width, \n",
    "        np.max(filtered_df['APP'])+APP_bin_width,\n",
    "        step=APP_bin_width),\n",
    "    density=fit_to_pdf,\n",
    "    histtype='step',\n",
    "    color='blue')\n",
    "\n",
    "if fit_to_pdf:\n",
    "    fit_x = np.linspace(\n",
    "        0,\n",
    "        max(       \n",
    "            APP_outlier_threshold,\n",
    "            np.max(filtered_df['APP'])\n",
    "        ),\n",
    "        1000\n",
    "    )\n",
    "    plt.plot(\n",
    "        fit_x,\n",
    "        distribution.pdf(\n",
    "            fit_x,\n",
    "            *distribution.fit(filtered_df['APP'])\n",
    "        ),\n",
    "        label=\"Fit to 'w/ bursts'\",\n",
    "        color='blue'\n",
    "    )\n",
    "\n",
    "plt.hist(\n",
    "    filtered_df['burstless_APP'], \n",
    "    label='w/o bursts',\n",
    "    bins=np.arange(\n",
    "        np.min(filtered_df['APP'])-APP_bin_width, \n",
    "        np.max(filtered_df['APP'])+APP_bin_width,\n",
    "        step=APP_bin_width),\n",
    "    density=fit_to_pdf,\n",
    "    histtype='step',\n",
    "    color='black')\n",
    "\n",
    "plt.axvline(\n",
    "    APP_outlier_threshold,\n",
    "    color='red',\n",
    "    label='Outlier threshold'\n",
    ")\n",
    "plt.xlim(\n",
    "    0,\n",
    "    APP_outlier_threshold+(0.5*APP_outlier_threshold)\n",
    ")\n",
    "plt.xlabel(\n",
    "    'Afterpulse probability',\n",
    "    fontsize=labels_fontsize\n",
    ")\n",
    "plt.ylabel(\n",
    "    'Hits' if not fit_to_pdf else 'Probability density',\n",
    "    fontsize=labels_fontsize\n",
    ")\n",
    "plt.xticks(fontsize=ticks_fontsize)\n",
    "plt.yticks(fontsize=ticks_fontsize)\n",
    "plt.title(\n",
    "    f\"Sets: {params['sets_to_analyze']} \\n w/ bursts - (\"\n",
    "    f\"{round(APP_mean, ndigits=ndigits)} +/- {round(APP_std, ndigits=ndigits)})\"\n",
    "    f\", w/o bursts - ({round(np.mean(filtered_df['burstless_APP']), ndigits=ndigits)}\"\n",
    "    f\" +/- {round(np.std(filtered_df['burstless_APP'], ddof=1), ndigits=ndigits)})\",\n",
    "    fontsize=title_fontsize\n",
    ")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Generate a table of strip_ID vs. sipm_location (still under development)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. For gain data (development in this section can benefit from the code in the gain analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_to_show = 'gain_in_#e-'\n",
    "additional_string = \"overvoltage_V=3.0\"\n",
    "table_ndigits = 1\n",
    "\n",
    "table = tools.strip_ID_vs_sipm_location_dataframe(\n",
    "    filtered_df[filtered_df['tray_no']==62],\n",
    "    field_to_show,\n",
    "    significant_figures=table_ndigits\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 2))\n",
    "ax.axis('off')\n",
    "ax.table(\n",
    "    cellText=[[f\"{val:.{1}e}\" for val in row] for row in table.values],\n",
    "    colLabels=table.columns, \n",
    "    rowLabels=[ ' '+str(aux)+' ' for aux in range(1,7)], \n",
    "    colWidths = [0.15 for aux in table.columns],\n",
    "    cellColours = [\n",
    "        [\n",
    "            tools.decide_colour(\n",
    "                val, \n",
    "                gain_mean, \n",
    "                gain_std, \n",
    "                discern_sign=True,\n",
    "                red_above=False\n",
    "            ) for val in row\n",
    "        ] for row in table.values\n",
    "    ],\n",
    "    cellLoc = 'center',\n",
    "    loc='center')\n",
    "ax.set_title(\n",
    "    f\"{field_to_show} \\n {additional_string} \\n Boards: \"\n",
    "    f\"{clustered_boards_string} \\n Mean +/- std: (\"\n",
    "    f\"{round(gain_mean, ndigits=ndigits)} +/- \"\n",
    "    f\"{round(gain_std, ndigits=ndigits)})\",\n",
    "    fontsize=title_fontsize\n",
    ")\n",
    "fig.show()\n",
    "#plt.savefig('tabla.png', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. For dark-noise data (development in this section can benefit from the code in the darknoise analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_to_show = 'DCR_mHz_per_mm2'\n",
    "table_ndigits = 1\n",
    "simple_colour_decide = lambda val : (1.,0.,0.) if val > 200 else ((1.,0.6,0.6) if val>150 else 'white')\n",
    "\n",
    "table = tools.strip_ID_vs_sipm_location_dataframe(\n",
    "    filtered_df,\n",
    "    field_to_show,\n",
    "    significant_figures=table_ndigits\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 2))\n",
    "ax.axis('off')\n",
    "ax.table(\n",
    "    cellText=table.values, \n",
    "    colLabels=table.columns, \n",
    "    rowLabels=[ ' '+str(aux)+' ' for aux in range(1,7)], \n",
    "    colWidths = [0.15 for aux in table.columns],\n",
    "    cellColours = [[ simple_colour_decide(val) for val in row] for row in table.values],\n",
    "    cellLoc = 'center',\n",
    "    loc='center'\n",
    ")\n",
    "ax.set_title(field_to_show)\n",
    "fig.show()\n",
    "#plt.savefig('tabla.png', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_to_show = 'XTP'\n",
    "table_ndigits = 2\n",
    "simple_colour_decide = lambda val : (1.,0.,0.) if val > 0.35 else ((1.,0.6,0.6) if val>0.2 else 'white')\n",
    "\n",
    "table = tools.strip_ID_vs_sipm_location_dataframe(\n",
    "    filtered_df,\n",
    "    field_to_show,\n",
    "    significant_figures=table_ndigits\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 2))\n",
    "ax.axis('off')\n",
    "ax.table(\n",
    "    cellText=table.values, \n",
    "    colLabels=table.columns, \n",
    "    rowLabels=[ ' '+str(aux)+' ' for aux in range(1,7)], \n",
    "    colWidths = [0.15 for aux in table.columns],\n",
    "    cellColours = [[ simple_colour_decide(val) for val in row] for row in table.values],\n",
    "    cellLoc = 'center',\n",
    "    loc='center'\n",
    ")\n",
    "ax.set_title(field_to_show)\n",
    "fig.show()\n",
    "#plt.savefig('tabla.png', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_to_show = 'APP'\n",
    "table_ndigits = 3\n",
    "bicolour_decide = lambda val : (1.,0.,0.) if val > 0.05 else ((1.,0.6,0.6) if val>0.04 else 'white')\n",
    "simple_colour_decide = lambda val : (1.,0.,0.) if val > 0.05 else  'white'\n",
    "\n",
    "table = tools.strip_ID_vs_sipm_location_dataframe(\n",
    "    filtered_df,\n",
    "    field_to_show,\n",
    "    significant_figures=table_ndigits\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 2))\n",
    "ax.axis('off')\n",
    "ax.table(\n",
    "    cellText=table.values, \n",
    "    colLabels=table.columns, \n",
    "    rowLabels=[ ' '+str(aux)+' ' for aux in range(1,7)], \n",
    "    colWidths = [0.15 for aux in table.columns],\n",
    "    cellColours = [[ simple_colour_decide(val) for val in row] for row in table.values],\n",
    "    cellLoc = 'center',\n",
    "    loc='center'\n",
    ")\n",
    "ax.set_title(field_to_show)\n",
    "fig.show()\n",
    "#plt.savefig('tabla.png', bbox_inches='tight', pad_inches=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "massibo_ana_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
