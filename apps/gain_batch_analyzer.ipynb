{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import constants as spcon\n",
    "from matplotlib import pyplot as plt\n",
    "from reportlab.lib import colors\n",
    "import tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from massibo_ana.postprocess.PDFGenerator import PDFGenerator\n",
    "import massibo_ana.utils.custom_exceptions as cuex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load the input parameters and change the WD to the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write here the ABSOLUTE path to the input parameters file\n",
    "input_parameters_filepath = ''\n",
    "\n",
    "with open(\n",
    "        input_parameters_filepath,\n",
    "        \"r\",\n",
    "        encoding=\"utf-8\"\n",
    "    ) as file:\n",
    "        \n",
    "        params = yaml.safe_load(file)\n",
    "\n",
    "os.chdir(params['workspace_dir'])\n",
    "load_dir = \"load/\"\n",
    "summary_dir = \"summary/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Read the waveforms, rebin, compute baseline and flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gainmeas_objects = tools.build_list_of_SiPMMeas_objects(\n",
    "    load_dir,\n",
    "    params['strips_to_analyze'],\n",
    "    params['analyzable_marks'],\n",
    "    is_gain_meas=True,\n",
    "    verbose=params['verbose']\n",
    ")\n",
    "\n",
    "if len(gainmeas_objects) == 0:\n",
    "    raise Exception(\n",
    "        \"Not a single GainMeas object was found coming from \"\n",
    "        f\"a board with a strip ID within {params['strips_to_analyze']} \"\n",
    "        f\"and with a mark within {params['analyzable_marks']}.\"\n",
    "    )\n",
    "\n",
    "analysis_reliability = [2] * len(gainmeas_objects)\n",
    "\n",
    "for i, gno in enumerate(gainmeas_objects):\n",
    "\n",
    "    gno.rebin(params['merged_points'])\n",
    "\n",
    "    if len(gno.Waveforms) < params['minimum_number_of_waveforms']:\n",
    "        analysis_reliability[i] = 0\n",
    "\n",
    "    # It is important to compute a reliable baseline before integrating,\n",
    "    # because the baseline is subtracted from the signal prior to integration.\n",
    "    gno.Waveforms.compute_first_peak_baseline(\n",
    "        signal_fraction_for_median_cutoff=params['signal_fraction_for_median_cutoff'],\n",
    "        half_width_about_median=params['half_width_about_median'],\n",
    "    )\n",
    "\n",
    "    if params['flip_about_baseline']:\n",
    "        gno.Waveforms.flip_about_baseline()\n",
    "\n",
    "# Order the waveform sets according to their strip IDs\n",
    "gainmeas_objects = tools.order_list_of_SiPMMeas_objects(gainmeas_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(set([gno.Overvoltage_V for gno in gainmeas_objects])) > 3:\n",
    "    raise Exception(\n",
    "        \"There are more than 3 different overvoltage \"\n",
    "        \"values. This is not supported.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Start the PDF report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params['generate_report']:\n",
    "\n",
    "    pdf_chunks_filepaths_generator = PDFGenerator.PDF_chunk_filepath(\n",
    "        summary_dir,\n",
    "        params['report_output_filename']\n",
    "    )\n",
    "    \n",
    "    aux = next(pdf_chunks_filepaths_generator)\n",
    "    pdf_reports_filepaths = [aux]\n",
    "    report_pdf = PDFGenerator(aux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Run the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(gainmeas_objects)):\n",
    "\n",
    "    if params['verbose']:\n",
    "        print(\n",
    "            f\"Integrating the ({len(gainmeas_objects[idx].Waveforms)}) \"\n",
    "            f\"waveforms for the {idx+1}-th \"\n",
    "            f\"(/{len(gainmeas_objects)}) SiPM data - \"\n",
    "            f\"{gainmeas_objects[idx].get_title()}\"\n",
    "        )\n",
    "\n",
    "    integration_lower_lim_s = \\\n",
    "        gainmeas_objects[idx].Waveforms.find_mean_beginning_of_raise(\n",
    "            signal_fraction_for_median_cutoff=params['signal_fraction_for_median_cutoff'],\n",
    "            tolerance=params['rising_edge_tolerance'],\n",
    "            # Return a time value, which we assume it is in seconds\n",
    "            return_iterator=False\n",
    "        ) + params['integration_lower_lim_correction_s']\n",
    "\n",
    "    integration_upper_lim_s = integration_lower_lim_s + params['integration_lim_width_s']\n",
    "\n",
    "    # WARNING: Note that here you are setting the input resistance of the DAQ and the\n",
    "    # amplification factor of the readout system. Check help(GainMeas.integrate).\n",
    "    gainmeas_objects[idx].integrate(\n",
    "        input_resistance_in_ohms=params['input_resistance_in_ohms'],\n",
    "        system_amplification_factor=params['system_amplification_factor'],\n",
    "        integration_lower_lim=integration_lower_lim_s,\n",
    "        integration_upper_lim=integration_upper_lim_s\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Fit the gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every gain measurement, the gaussian fits are done for every\n",
    "# element in a bidimensional grid of (bins_no x peaks_to_detect).\n",
    "# Take the fit with the lowest error, we are then identifying the\n",
    "# fit with the lowest error figure-of-merit. You can check the\n",
    "# details of such computation in the error_fom variable below.\n",
    "# Note that the errors coming from the gaussian fits are normalized\n",
    "# to the number of fitted peaks. Since we are comparing errors among\n",
    "# fits with different number of fitted peaks, the error should be\n",
    "# computed on a peak basis, so that fits with less peaks are not\n",
    "# systematically favored.\n",
    "\n",
    "errors = {}\n",
    "\n",
    "# First scan which is 'quicker' because we are not producing plots, i.e. we are\n",
    "# setting gain_fit_axes and histogram_fit_axes to None in the fit_gain method.\n",
    "for i in range(len(gainmeas_objects)):\n",
    "\n",
    "    if params['verbose']:\n",
    "        print(\n",
    "            f\"Searching for an optimal gain-fit for the \"\n",
    "            f\"{i+1}-th (/{len(gainmeas_objects)}) SiPM \"\n",
    "            f\"data - {gainmeas_objects[i].get_title()}\"\n",
    "        )\n",
    "\n",
    "    errors[i] = {}\n",
    "    for peaks_to_detect in reversed(\n",
    "        range(\n",
    "            params['min_peaks_to_detect'],\n",
    "            params['max_peaks_to_detect']+1\n",
    "        )\n",
    "    ):\n",
    "\n",
    "        errors[i][peaks_to_detect] = {}\n",
    "        for bins_no in np.linspace(\n",
    "            params['min_bins_no'],\n",
    "            params['max_bins_no'],\n",
    "            params['bins_no_points']\n",
    "        ):\n",
    "\n",
    "            errors[i][peaks_to_detect][int(bins_no)] = {}\n",
    "            try:\n",
    "                gain_popt, gain_stderr, histogram_popt, histogram_pcov = \\\n",
    "                    gainmeas_objects[i].fit_gain(\n",
    "                        has_pedestal=True,\n",
    "                        peaks_to_detect=peaks_to_detect,\n",
    "                        peaks_to_fit=None,\n",
    "                        bins_no=int(bins_no),\n",
    "                        # Should be small enough so that the sampling is fine enough\n",
    "                        # for the (mean-gaussian_fit_std_no*std, mean+gaussian_fit_std_no*std)\n",
    "                        # interval to contain enough points for each fit (each gaussian\n",
    "                        # fit has three free parameters), but big enough so that the\n",
    "                        # binning is coarse enough for the previous-peak-detection not\n",
    "                        # to find more than one peak per actual-charge-peak.\n",
    "                        starting_fraction=params['peak_search_starting_fraction'],\n",
    "                        step_fraction=params['peak_search_step_fraction'],\n",
    "                        minimal_prominence_wrt_max=params['minimal_prominence_wrt_max'],\n",
    "                        std_no=params['gaussian_fit_std_no'],\n",
    "                        gain_fit_axes=None,\n",
    "                        histogram_fit_axes=None\n",
    "                )\n",
    "\n",
    "                if params['verbose']:\n",
    "                    print(\n",
    "                        \"Found the requested number of peaks \"\n",
    "                        f\"({peaks_to_detect}) for the {i+1}-th \"\n",
    "                        f\"(/{len(gainmeas_objects)}) measurement \"\n",
    "                        f\"({gainmeas_objects[i].get_title()}) \"\n",
    "                        f\"with peaks_to_detect={peaks_to_detect} and \"\n",
    "                        f\"bins_no={bins_no}.\"\n",
    "                    )\n",
    "                \n",
    "            except cuex.RequestedPeaksNotFound:\n",
    "                if params['verbose']:\n",
    "                    print(\n",
    "                        \"Couldn't find the requested number of peaks \"\n",
    "                        f\"({peaks_to_detect}) for the {i+1}-th \"\n",
    "                        f\"(/{len(gainmeas_objects)}) measurement \"\n",
    "                        f\"({gainmeas_objects[i].get_title()}) \"\n",
    "                        f\"with peaks_to_detect={peaks_to_detect} and \"\n",
    "                        f\"bins_no={bins_no}. A different (peaks_to_detect, \"\n",
    "                        \"bins_no) combination will be tried.\"\n",
    "                    )\n",
    "                continue\n",
    "\n",
    "            except RuntimeError as e:\n",
    "                if params['verbose']:\n",
    "                    print(\n",
    "                        \"Encountered the following RunTime error while \"\n",
    "                        f\"fitting the {i+1}-th (/{len(gainmeas_objects)}) \"\n",
    "                        f\"measurement ({gainmeas_objects[i].get_title()}) \"\n",
    "                        f\"with peaks_to_detect={peaks_to_detect} \"\n",
    "                        f\"and bins_no={bins_no}: \\n\\t -> {e} \\n A different \"\n",
    "                        \"(peaks_to_detect, bins_no) combination will be \"\n",
    "                        \"tried.\"\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "            gaussian_fit_error = 0.0\n",
    "            for cov_matrix in histogram_pcov:\n",
    "                gaussian_fit_error += np.sum(np.sqrt(np.diag(cov_matrix)))\n",
    "\n",
    "            # If any of the numbers involved in the following computation is np.Inf,\n",
    "            # it will be understood as an infinite error, and it won't become the\n",
    "            # optimal error. Yes, np.Inf is well-defined under addition,\n",
    "            # multiplication and comparison.\n",
    "            errors[i][peaks_to_detect][int(bins_no)]['gaussian_fit_error'] = \\\n",
    "                gaussian_fit_error/len(histogram_pcov)\n",
    "            errors[i][peaks_to_detect][int(bins_no)]['linear_fit_error'] = \\\n",
    "                gain_stderr[0]+gain_stderr[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the mean and standard deviation of the linear and gaussian\n",
    "# fit errors. This step is necessary to later normalize both errors\n",
    "# so that comparison among both is meaningful.\n",
    "linear_fit_error_samples = {}\n",
    "gaussian_fit_error_samples = {}\n",
    "\n",
    "for i in errors.keys():\n",
    "    # linear_fit_error_samples[i] is a list of linear-fit error\n",
    "    # samples for the i-th SiPM data. The same data structure is\n",
    "    # used for gaussian_fit_error_samples[i]\n",
    "    linear_fit_error_samples[i] = []\n",
    "    gaussian_fit_error_samples[i] = []\n",
    "\n",
    "    for peaks_to_detect in errors[i].keys():\n",
    "        for bins_no in errors[i][peaks_to_detect].keys():\n",
    "            try:\n",
    "                # In the previous code, the linear fit error and the gaussian\n",
    "                # fit error are added to the errors dictionary at the same time.\n",
    "                # They are mutually defined, i.e. if one is not defined, the other\n",
    "                # one is not defined either. Therefore, we can safely use the\n",
    "                # following try-except block for both errors at the same time.\n",
    "                linear_fit_error_samples[i].append(\n",
    "                    errors[i][peaks_to_detect][bins_no]['linear_fit_error']\n",
    "                )\n",
    "                gaussian_fit_error_samples[i].append(\n",
    "                    errors[i][peaks_to_detect][bins_no]['gaussian_fit_error']\n",
    "                )\n",
    "            except KeyError:\n",
    "                pass\n",
    "\n",
    "\n",
    "for i in linear_fit_error_samples.keys():\n",
    "# Linear fit errors normally contain some zeros, which come from\n",
    "# situations where only two peaks were fit. We shall not count these in.\n",
    "    linear_fit_error_samples[i] = np.array(\n",
    "        tools.filter_out_zeros_and_infs(\n",
    "            linear_fit_error_samples[i]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Gaussian fit errors normally contain some\n",
    "    # infinite entries. We shall not count these in.\n",
    "    gaussian_fit_error_samples[i] = np.array(\n",
    "        tools.filter_out_zeros_and_infs(\n",
    "            gaussian_fit_error_samples[i]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # If after filtering out the infinities, there are\n",
    "    # no gaussian-fit-error samples left, then we tag\n",
    "    # the analysis for this GainMeas as 1-reliable\n",
    "    if len(gaussian_fit_error_samples[i]) == 0:\n",
    "        analysis_reliability[i] = 1\n",
    "\n",
    "        if params['verbose']:\n",
    "            print(\n",
    "                \"WARNING: Not a single (peaks_to_detect, bins_no) \"\n",
    "                \"combination allowed a finite-error gaussian \"\n",
    "                f\"peaks-fit of the charge histogram for the {i+1}-th \"\n",
    "                f\"(/{len(gainmeas_objects)}) SiPM data - \"\n",
    "                f\"{gainmeas_objects[i].get_title()}. The analysis for \"\n",
    "                \"this GainMeas has been tagged as 1-reliable.\"\n",
    "            )\n",
    "        \n",
    "linear_fit_error_mean = {}\n",
    "linear_fit_error_std = {}\n",
    "gaussian_fit_error_mean = {}\n",
    "gaussian_fit_error_std = {}\n",
    "\n",
    "for i in errors.keys():\n",
    "    if analysis_reliability[i] > 1:\n",
    "        # linear_fit_error_mean[i] and linear_fit_error_std[i] may be NaN\n",
    "        # if there are no samples left after filtering out the null values\n",
    "        # associated to the 2-peaks fits.\n",
    "        linear_fit_error_mean[i] = np.mean(linear_fit_error_samples[i])\n",
    "        linear_fit_error_std[i] = np.std(linear_fit_error_samples[i])\n",
    "        # gaussian_fit_error_mean[i] is always defined, because we made\n",
    "        # sure that that 2-reliable analyses have at least one finite\n",
    "        # gaussian fit\n",
    "        gaussian_fit_error_mean[i] = np.mean(gaussian_fit_error_samples[i])\n",
    "        # gaussian_fit_error_std[i] may be null if only one\n",
    "        # (peaks_to_detect, bins_no) combination was found to give a finite\n",
    "        # gaussian fit error\n",
    "        gaussian_fit_error_std[i] = np.std(gaussian_fit_error_samples[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every gain measurement, scan through all of the (peaks_to_detect, bins_no)\n",
    "# combinations to find the one with the smallest error. To compute a meaningful \n",
    "# error figure-of-merit which combines both the linear and gaussian fit errors,\n",
    "# normalize each contribution by the mean and standard deviation of the corresponding\n",
    "# distribution.\n",
    "optimal_parameters = {\n",
    "    i: {\n",
    "        'peaks_to_detect': None,\n",
    "        'bins_no': None,\n",
    "        'error_fom': None\n",
    "    } for i in range(len(gainmeas_objects))\n",
    "}\n",
    "\n",
    "for i in range(len(gainmeas_objects)):\n",
    "\n",
    "    if analysis_reliability[i] > 1:\n",
    "\n",
    "        fConsiderLinearFitError = False\n",
    "        # If all of the linear fits for this SiPM data \n",
    "        # considered just two peaks, then all of the\n",
    "        # linear-fit error entries for this SiPM data\n",
    "        # are zero, and they were filtered out. Therefore,\n",
    "        # np.mean() and np.std() should have resulted in\n",
    "        # NaN. If that is the case, do not consider the\n",
    "        # linear fit error in the error figure-of-merit.\n",
    "        if not math.isnan(linear_fit_error_mean[i]) and \\\n",
    "            not math.isnan(linear_fit_error_std[i]):\n",
    "            fConsiderLinearFitError = True\n",
    "\n",
    "        fGaussianFitErrorStdIsZero = True if \\\n",
    "            gaussian_fit_error_std[i] == 0. else False\n",
    "\n",
    "        for peaks_to_detect in errors[i].keys():\n",
    "            for bins_no in errors[i][peaks_to_detect].keys():\n",
    "                try:\n",
    "                    # N.B. 1: The if-case happens if only 2 peaks were fitted. In\n",
    "                    # this case, compensate by taking the mean of the normalized\n",
    "                    # distribution (i.e. zero), so that 2-peaks fits are not\n",
    "                    # systematically favored. In the else-case, (the computed linear\n",
    "                    # fit error is not null), normalize the error.\n",
    "                    # N.B. 2: It may happen that some of the (peaks_to_detect, bins_no)\n",
    "                    # combinations worked out for this SiPM data, thus giving a\n",
    "                    # True value for the fConsiderLinearFitError flag, but that the\n",
    "                    # current (peaks_to_detect, bins_no) combination only fitted two\n",
    "                    # peaks, thus giving a linear fit error of zero. This is the\n",
    "                    # exact case we are managing with the if-else below.\n",
    "                    if fConsiderLinearFitError:\n",
    "                        linear_fit_error = 0.0 \\\n",
    "                        if errors[i][peaks_to_detect][bins_no]['linear_fit_error'] == 0. \\\n",
    "                        else (errors[i][peaks_to_detect][bins_no]['linear_fit_error'] - \\\n",
    "                            linear_fit_error_mean[i])/linear_fit_error_std[i]\n",
    "\n",
    "                    # Note that this block of code is executed only if the\n",
    "                    # analysis reliability is greater than 1, i.e. there was\n",
    "                    # at least one gaussian fit with a finite error. This\n",
    "                    # ensures that the gaussian_fit_error_mean is well-defined.\n",
    "                    # However, the gaussian_fit_error_std might still be zero if\n",
    "                    # only (exactly) one gaussian fit resulted to have a finite\n",
    "                    # error. If that is the case, only the gaussian_fit_error\n",
    "                    # associated to the finite-error fit will be finite, and so,\n",
    "                    # we can consider whichever std (p.e. 1.0) to normalize\n",
    "                    # the gaussian_fit_error since only the finite-error fit\n",
    "                    # will give a finite error figure-of-merit.\n",
    "                    gaussian_fit_error = (\n",
    "                        errors[i][peaks_to_detect][bins_no]['gaussian_fit_error'] - \\\n",
    "                        gaussian_fit_error_mean[i]\n",
    "                        )/(gaussian_fit_error_std[i] if not fGaussianFitErrorStdIsZero else 1.0)\n",
    "                    \n",
    "                # Happens if a cuex.RequestedPeaksNotFound or a\n",
    "                # RunTime error was triggered by GainMeas.fit_gain()\n",
    "                # for this (peaks_to_detect, bins_no) combination\n",
    "                except KeyError:\n",
    "                    continue\n",
    "                \n",
    "                candidate_error_fom = \\\n",
    "                    gaussian_fit_error if not fConsiderLinearFitError else \\\n",
    "                    linear_fit_error + gaussian_fit_error\n",
    "\n",
    "                try:\n",
    "                    if candidate_error_fom < optimal_parameters[i]['error_fom']:\n",
    "                        optimal_parameters[i]['error_fom'] = candidate_error_fom\n",
    "                        optimal_parameters[i]['peaks_to_detect'] = peaks_to_detect\n",
    "                        optimal_parameters[i]['bins_no'] = bins_no\n",
    "\n",
    "                # Happens if optimal_parameters[i]['error_fom'] was still None\n",
    "                except TypeError:\n",
    "                    optimal_parameters[i]['error_fom'] = candidate_error_fom\n",
    "                    optimal_parameters[i]['peaks_to_detect'] = peaks_to_detect\n",
    "                    optimal_parameters[i]['bins_no'] = bins_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, for each gain measurement, we are trying a (peaks_to_detect, bins_no)\n",
    "# combination that we know for sure will work. So there's no need to handle\n",
    "# exceptions here.\n",
    "\n",
    "gain_fit_results = {\n",
    "    i: {\n",
    "        'gain_popt': None,\n",
    "        'gain_stderr': None,\n",
    "        'histogram_popt': None,\n",
    "        'histogram_pcov': None,\n",
    "        'figure': None\n",
    "    } for i in range(len(gainmeas_objects))\n",
    "}\n",
    "\n",
    "for i in range(len(gainmeas_objects)):\n",
    "\n",
    "    try:\n",
    "        aux_plot_charge_range = None if params['plot_charge_histogram_range'] is None \\\n",
    "            else params['plot_charge_histogram_range'][gainmeas_objects[i].Overvoltage_V]\n",
    "    except KeyError:\n",
    "        raise cuex.InsufficientParameters(\n",
    "            f\"No charge histogram range defined for the \"\n",
    "            f\"overvoltage {gainmeas_objects[i].Overvoltage_V} V. \"\n",
    "            \"Please, check the input parameters file.\" \n",
    "        )\n",
    "\n",
    "    aux_fig, aux_ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    # In this case, simply plot the charge histogram in linear and\n",
    "    # logarithmic scales, without gaussian fits nor linear gain-fit\n",
    "    if analysis_reliability[i] < 2:\n",
    "        if params['verbose']:\n",
    "            print(\n",
    "                f\"Skipping the gain computation for the {i+1}-th \"\n",
    "                f\"(/{len(gainmeas_objects)}) SiPM data \"\n",
    "                f\"({gainmeas_objects[i].get_title()}), which was \"\n",
    "                \"tagged as 1-reliable.\"\n",
    "            )\n",
    "\n",
    "            _, _, _ = aux_ax[0].hist(\n",
    "                gainmeas_objects[i].ChargeEntries,\n",
    "                bins_no,\n",
    "                log=False,\n",
    "                histtype=\"step\")\n",
    "            \n",
    "            aux_ax[0].set_xlabel(f\"Charge (C)\")\n",
    "            aux_ax[0].set_ylabel(f\"Hits\")\n",
    "            aux_ax[0].set_xlim(aux_plot_charge_range)\n",
    "            aux_ax[0].set_title('Linear charge histogram')\n",
    "            aux_ax[0].grid()\n",
    "\n",
    "            _, _, _ = aux_ax[1].hist(\n",
    "                gainmeas_objects[i].ChargeEntries,\n",
    "                bins_no,\n",
    "                log=True,\n",
    "                histtype=\"step\")\n",
    "            \n",
    "            aux_ax[1].set_xlabel(f\"Charge (C)\")\n",
    "            aux_ax[1].set_ylabel(f\"Hits\")\n",
    "            aux_ax[1].set_xlim(aux_plot_charge_range)\n",
    "            aux_ax[1].set_title('Logarithmic charge histogram')\n",
    "            aux_ax[1].grid()\n",
    "            aux_ax[1].set_ylim(10**-1)\n",
    "\n",
    "    else:\n",
    "        if params['verbose']:\n",
    "            print(\n",
    "                f\"Computing the gain for the {i+1}-th \"\n",
    "                f\"(/{len(gainmeas_objects)}) SiPM data \"\n",
    "                f\"({gainmeas_objects[i].get_title()}) with peaks_\"\n",
    "                f\"to_detect={optimal_parameters[i]['peaks_to_detect']}\"\n",
    "                f\" and bins_no={optimal_parameters[i]['bins_no']}.\"\n",
    "            )\n",
    "\n",
    "        gain_popt, gain_stderr, histogram_popt, histogram_pcov = \\\n",
    "            gainmeas_objects[i].fit_gain(\n",
    "                has_pedestal=True,\n",
    "                peaks_to_detect=optimal_parameters[i]['peaks_to_detect'],\n",
    "                peaks_to_fit=None,\n",
    "                bins_no=optimal_parameters[i]['bins_no'],\n",
    "                starting_fraction=params['peak_search_starting_fraction'],\n",
    "                step_fraction=params['peak_search_step_fraction'],\n",
    "                minimal_prominence_wrt_max=params['minimal_prominence_wrt_max'],\n",
    "                std_no=params['gaussian_fit_std_no'],\n",
    "                gain_fit_axes=aux_ax[0],\n",
    "                errorbars_scaling=10.,\n",
    "                histogram_fit_axes=aux_ax[1],\n",
    "                logarithmic_plot=params['logarithmic_charge_histogram'],\n",
    "                histogram_axes_title=gainmeas_objects[i].get_title(abbreviate=True),\n",
    "                gaussian_plot_npoints=200,\n",
    "                plot_charge_range=aux_plot_charge_range,\n",
    "                plot_histogram_fit=True\n",
    "        )\n",
    "\n",
    "        gain_fit_results[i]['gain_popt'] = gain_popt\n",
    "        gain_fit_results[i]['gain_stderr'] = gain_stderr\n",
    "        gain_fit_results[i]['histogram_popt'] = histogram_popt\n",
    "        gain_fit_results[i]['histogram_pcov'] = histogram_pcov\n",
    "\n",
    "    # Save the figure in any case\n",
    "    gain_fit_results[i]['figure'] = aux_fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Report results of integration and gain-fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params['generate_report']:\n",
    "\n",
    "    for idx in range(len(gainmeas_objects)):\n",
    "\n",
    "        if params['verbose']:\n",
    "            print(\n",
    "                \"Reporting the integrated waveforms for the \"\n",
    "                f\"{idx+1}-th (/{len(gainmeas_objects)}) SiPM data \"\n",
    "                f\"- {gainmeas_objects[idx].get_title()}\"\n",
    "            )\n",
    "\n",
    "        report_pdf.add_text(\n",
    "            f\"Iterator {idx}, {gainmeas_objects[idx].get_title()}\",\n",
    "            horizontal_pos_frac=None,\n",
    "            vertical_pos_frac=0.95,\n",
    "            max_width_frac=0.9,\n",
    "            font_size=params['title_font_size'],\n",
    "            horizontally_center=True\n",
    "        )\n",
    "\n",
    "        report_pdf.add_text(\n",
    "            f\"Persistency plot w/ integration limits\",\n",
    "            horizontal_pos_frac=None,\n",
    "            vertical_pos_frac=0.88,\n",
    "            max_width_frac=0.9,\n",
    "            font_size=params['subtitle_font_size'],\n",
    "            horizontally_center=True\n",
    "        )\n",
    "\n",
    "        report_pdf.add_text(\n",
    "            f\"Integrated {len(gainmeas_objects[idx].Waveforms)}\"\n",
    "            \" fast frames\",\n",
    "            horizontal_pos_frac=None,\n",
    "            vertical_pos_frac=0.84,\n",
    "            max_width_frac=0.9,\n",
    "            font_size=params['text_font_size'],\n",
    "            horizontally_center=True\n",
    "        )\n",
    "\n",
    "        if analysis_reliability[idx] == 0:\n",
    "            report_pdf.add_text(\n",
    "                f\"WARNING: The analysis for this GainMeas has \"\n",
    "                \"been tagged as 0-reliable because this measurement\"\n",
    "                f\" contains less than {params['minimum_number_of_waveforms']}\"\n",
    "                \" waveforms\",\n",
    "                horizontal_pos_frac=0.40,\n",
    "                vertical_pos_frac=0.89,\n",
    "                max_width_frac=0.6,\n",
    "                font_size=params['text_font_size']-2,\n",
    "                font_color=colors.red,\n",
    "                horizontally_center=False\n",
    "            )\n",
    "        elif analysis_reliability[idx] == 1:\n",
    "            report_pdf.add_text(\n",
    "                f\"WARNING: The analysis for this GainMeas has \"\n",
    "                \"been tagged as 1-reliable because the charge \"\n",
    "                f\"histogram could not be fit.\",\n",
    "                horizontal_pos_frac=0.40,\n",
    "                vertical_pos_frac=0.85,\n",
    "                max_width_frac=0.6,\n",
    "                font_size=params['text_font_size']-2,\n",
    "                font_color=colors.red,\n",
    "                horizontally_center=False\n",
    "            )\n",
    "\n",
    "        aux = gainmeas_objects[idx].Waveforms.plot(\n",
    "            wvfs_to_plot=params['superimposed_waveforms'],\n",
    "            ylim=tuple(params['persistency_plot_range']) if params['persistency_plot_range'] is not None else None,\n",
    "            x0=[],\n",
    "            y0=[],\n",
    "            subtract_baseline=params['subtract_baseline_in_persistency_plot'],\n",
    "            randomize=True,\n",
    "            fig_title=f\"Iterator {idx}, {gainmeas_objects[idx].get_title(abbreviate=True)}\\n\"\n",
    "            f\"({params['superimposed_waveforms']} waveforms)\",\n",
    "            mode='superposition',\n",
    "            title_fontsize=params['text_font_size'],\n",
    "            wvf_linewidth=params['persistency_wvf_linewidth'],\n",
    "            show_plots=False\n",
    "        )\n",
    "\n",
    "        report_pdf.add_plot(\n",
    "            aux[0],\n",
    "            horizontal_pos_frac=None,\n",
    "            vertical_pos_frac=0.32,\n",
    "            plot_width_wrt_page_width=0.75,\n",
    "            horizontally_center=True\n",
    "        )\n",
    "\n",
    "        if analysis_reliability[idx] > 0:\n",
    "            if params['verbose']:\n",
    "                print(\n",
    "                    \"Reporting the gain-fit results for the \"\n",
    "                    f\"{idx+1}-th (/{len(gainmeas_objects)}) SiPM data \"\n",
    "                    f\"- {gainmeas_objects[idx].get_title()}.\"\n",
    "                )\n",
    "\n",
    "            report_pdf.add_text(\n",
    "                f\"Fit-gain results\"\n",
    "                if analysis_reliability[idx] == 2 else\n",
    "                f\"Not fitted charge histogram\",\n",
    "                horizontal_pos_frac=None,\n",
    "                vertical_pos_frac=0.35,\n",
    "                max_width_frac=0.9,\n",
    "                font_size=params['subtitle_font_size'],\n",
    "                horizontally_center=True\n",
    "            )\n",
    "\n",
    "            report_pdf.add_plot(\n",
    "                gain_fit_results[idx]['figure'],\n",
    "                horizontal_pos_frac=None,\n",
    "                vertical_pos_frac=-0.1,\n",
    "                plot_width_wrt_page_width=0.8,\n",
    "                horizontally_center=True\n",
    "            )\n",
    "        else:\n",
    "            if params['verbose']:\n",
    "                print(\n",
    "                    \"Skipping the report of the gain-fit results for \"\n",
    "                    f\"the {idx+1}-th (/{len(gainmeas_objects)}) SiPM \"\n",
    "                    f\"data ({gainmeas_objects[idx].get_title()}) \"\n",
    "                    \"which was tagged as 0-reliable.\"\n",
    "                )\n",
    "    \n",
    "        started_a_new_pdf, aux = PDFGenerator.smart_close_page(\n",
    "            report_pdf,\n",
    "            params['max_pages_per_pdf_chunk'],\n",
    "            pdf_chunks_filepaths_generator\n",
    "        )\n",
    "\n",
    "        if started_a_new_pdf:\n",
    "            del report_pdf\n",
    "            report_pdf = aux\n",
    "            pdf_reports_filepaths.append(report_pdf.OutputFilepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Generate output dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = None\n",
    "fIsFirst = True\n",
    "\n",
    "for i in range(len(gainmeas_objects)):\n",
    "\n",
    "    aux = gainmeas_objects[i].output_summary(\n",
    "        additional_entries= {\n",
    "            \"merged_points\": params['merged_points'],\n",
    "            \"signal_fraction_for_median_cutoff\": params['signal_fraction_for_median_cutoff'], \n",
    "            \"rising_edge_tolerance\": params['rising_edge_tolerance'],\n",
    "            \"integration_lower_lim_correction_s\": params['integration_lower_lim_correction_s'],\n",
    "            \"integration_lim_width_s\": params['integration_lim_width_s'],\n",
    "            \"integration_lower_lim_s\": integration_lower_lim_s,\n",
    "            \"integration_upper_lim_s\": integration_upper_lim_s,\n",
    "            \"input_resistance_in_ohms\": params['input_resistance_in_ohms'],\n",
    "            \"system_amplification_factor\": params['system_amplification_factor'],\n",
    "            \"peak_search_starting_fraction\": params['peak_search_starting_fraction'],\n",
    "            \"peak_search_step_fraction\": params['peak_search_step_fraction'],\n",
    "            \"minimal_prominence_wrt_max\": params['minimal_prominence_wrt_max'],\n",
    "            \"gaussian_fit_std_no\": params['gaussian_fit_std_no'],\n",
    "            \"min_peaks_to_detect\": params['min_peaks_to_detect'],\n",
    "            \"max_peaks_to_detect\": params['max_peaks_to_detect'],\n",
    "            \"min_bins_no\": params['min_bins_no'],\n",
    "            \"max_bins_no\": params['max_bins_no'],\n",
    "            \"bins_no_points\": params['bins_no_points'],\n",
    "            \"gain_in_#e-\": gain_fit_results[i]['gain_popt'][0]/spcon.e \n",
    "            if analysis_reliability[i] > 1 else float('nan'),\n",
    "            \"analysis_reliability\": analysis_reliability[i]\n",
    "        },\n",
    "        folderpath=None,\n",
    "        include_analysis_results=True if analysis_reliability[i] > 0 else False,\n",
    "        overwrite=params['json_overwrite'],\n",
    "        indent=params['indent'],\n",
    "        verbose=params['verbose'])\n",
    "    \n",
    "    if fIsFirst:\n",
    "        # Convert the model data to a dictionary of lists\n",
    "        data = {key: [value] for key, value in aux.items()}\n",
    "        fIsFirst = False\n",
    "    else:\n",
    "        for key in data.keys():\n",
    "            data[key].append(aux[key])\n",
    "\n",
    "output_dataframe = pd.DataFrame(data)\n",
    "\n",
    "if params['verbose']:\n",
    "    print(\n",
    "        f\"Saving the output dataframe to \"\n",
    "        f\"{os.path.abspath(summary_dir)}/{params['output_dataframe_filename']}\"\n",
    "    )\n",
    "\n",
    "output_dataframe.to_csv(\n",
    "    os.path.join(\n",
    "        summary_dir,\n",
    "        params['output_dataframe_filename']+'.csv'\n",
    "    )\n",
    ")\n",
    "\n",
    "output_dataframe.to_pickle(\n",
    "    os.path.join(\n",
    "        summary_dir,\n",
    "        params['output_dataframe_filename']+'.pkl'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Report the gain resulting distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_to_show = 'gain_in_#e-'\n",
    "\n",
    "red_lightness = 0.7\n",
    "\n",
    "overvoltage_grouped_dataframes = {\n",
    "    key: group for key, group in output_dataframe.groupby('overvoltage_V')\n",
    "}\n",
    "gain_characteristics_with_overvoltage = {\n",
    "    key: {\n",
    "        'mean': np.mean(overvoltage_grouped_dataframes[key]['gain_in_#e-']),\n",
    "        'std': np.std(overvoltage_grouped_dataframes[key]['gain_in_#e-'])\n",
    "    } for key in overvoltage_grouped_dataframes.keys()\n",
    "}\n",
    "\n",
    "# Assuming that red_lightness and gain_characteristics_with_overvoltage are defined\n",
    "def colour_decide(\n",
    "        gain: float,\n",
    "        overvoltage_key: float,\n",
    "        std_number_soft: int,\n",
    "        std_number_hard: int\n",
    "        ):\n",
    "    \n",
    "    if math.isnan(gain):\n",
    "        return (0.8, 0.8, 0.)\n",
    "    elif gain <= gain_characteristics_with_overvoltage[overvoltage_key]['mean'] - \\\n",
    "        (std_number_hard * gain_characteristics_with_overvoltage[overvoltage_key]['std']):\n",
    "        return (1., 0., 0.)\n",
    "    elif gain <= gain_characteristics_with_overvoltage[overvoltage_key]['mean'] - \\\n",
    "        (std_number_soft * gain_characteristics_with_overvoltage[overvoltage_key]['std']):\n",
    "        return (1., red_lightness, red_lightness)\n",
    "    elif gain <= gain_characteristics_with_overvoltage[overvoltage_key]['mean'] + \\\n",
    "        (std_number_soft * gain_characteristics_with_overvoltage[overvoltage_key]['std']):\n",
    "        return 'white'\n",
    "    elif gain <= gain_characteristics_with_overvoltage[overvoltage_key]['mean'] + \\\n",
    "        (std_number_hard * gain_characteristics_with_overvoltage[overvoltage_key]['std']):\n",
    "        return (1., red_lightness, red_lightness)\n",
    "    else:\n",
    "        return (1., 0., 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params['generate_report']:\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=1,\n",
    "        ncols=1,\n",
    "        figsize=(15, 5)\n",
    "    )\n",
    "\n",
    "    aux_min_overvoltage = min(overvoltage_grouped_dataframes.keys())\n",
    "    aux_max_overvoltage = max(overvoltage_grouped_dataframes.keys())\n",
    "    gain_histograms_range = (\n",
    "        gain_characteristics_with_overvoltage[aux_min_overvoltage]['mean'] \\\n",
    "            - (20. * gain_characteristics_with_overvoltage[aux_min_overvoltage]['std']),\n",
    "        gain_characteristics_with_overvoltage[aux_max_overvoltage]['mean'] \\\n",
    "            + (20. * gain_characteristics_with_overvoltage[aux_max_overvoltage]['std'])\n",
    "    )\n",
    "\n",
    "    tools.plot_histogram(\n",
    "        axes,\n",
    "        *[\n",
    "            np.array(overvoltage_grouped_dataframes[overvoltage][field_to_show])\n",
    "            for overvoltage in overvoltage_grouped_dataframes.keys()\n",
    "        ],\n",
    "        bins=params['resulting_distributions_nbins'],\n",
    "        hist_range=gain_histograms_range,\n",
    "        density=False,\n",
    "        xlabel='Gain (# e-)',\n",
    "        ylabel='Hits',\n",
    "        legend_labels=[\n",
    "            f\"OV = {overvoltage} V, \"\n",
    "            r\"$\\mu = $\"\n",
    "            f\"{tools.scientific_notation_str(gain_characteristics_with_overvoltage[overvoltage]['mean'], ndigits=params['gain_mean_ndigits'])}, \"\n",
    "            r\"$\\sigma = $\"\n",
    "            f\"{tools.scientific_notation_str(gain_characteristics_with_overvoltage[overvoltage]['std'], ndigits=params['gain_std_ndigits'])}, \"\n",
    "            for overvoltage in overvoltage_grouped_dataframes.keys()\n",
    "        ],\n",
    "        figtitle=f\"Overvoltage-wise gain distributions\",\n",
    "        fontsize=params['text_font_size'],\n",
    "        colourful=True,\n",
    "    )\n",
    "\n",
    "    if params['plot_vertical_red_threshold']:\n",
    "        for overvoltage in overvoltage_grouped_dataframes.keys():\n",
    "            for factor in (-1., +1.):\n",
    "\n",
    "                axes.axvline(\n",
    "                    x=gain_characteristics_with_overvoltage[overvoltage]['mean'] + \\\n",
    "                        (factor * params['std_number_soft'] * gain_characteristics_with_overvoltage[overvoltage]['std']),\n",
    "                    color=(1., red_lightness, red_lightness),\n",
    "                    linestyle='-',\n",
    "                    linewidth=params['vertical_thresholds_linewidth']\n",
    "                )\n",
    "\n",
    "                axes.axvline(\n",
    "                    x=gain_characteristics_with_overvoltage[overvoltage]['mean'] + \\\n",
    "                        (factor * params['std_number_hard'] * gain_characteristics_with_overvoltage[overvoltage]['std']),\n",
    "                    color=(1., 0., 0.),\n",
    "                    linestyle='-',\n",
    "                    linewidth=params['vertical_thresholds_linewidth']\n",
    "                )\n",
    "\n",
    "    if params['verbose']:\n",
    "        print(f\"Reporting the gain distributions including all of the SiPMs\")\n",
    "\n",
    "    report_pdf.add_text(\n",
    "        f\"Gain resulting distributions\",\n",
    "        horizontal_pos_frac=None,\n",
    "        vertical_pos_frac=0.95,\n",
    "        max_width_frac=0.9,\n",
    "        font_size=params['title_font_size'],\n",
    "        horizontally_center=True\n",
    "    )\n",
    "\n",
    "    fig.tight_layout()\n",
    "    report_pdf.add_plot(\n",
    "        fig,\n",
    "        horizontal_pos_frac=None,\n",
    "        vertical_pos_frac=0.45,\n",
    "        plot_width_wrt_page_width=0.99,\n",
    "        horizontally_center=True\n",
    "    )\n",
    "\n",
    "    # Don't close the last page nor save the PDF\n",
    "    # yet, because we will place some tables in it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Report the gain result-tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming that there are only\n",
    "# three different overvoltages\n",
    "tables_vertical_pos_frac = (\n",
    "    0.3, 0.2, 0.1\n",
    ")\n",
    "\n",
    "if params['generate_report']:\n",
    "    \n",
    "    for i, overvoltage in enumerate(overvoltage_grouped_dataframes.keys()):\n",
    "\n",
    "        table = tools.strip_ID_vs_sipm_location_dataframe(\n",
    "            overvoltage_grouped_dataframes[overvoltage], \n",
    "            field_to_show, \n",
    "            significant_figures=params['gain_mean_ndigits']\n",
    "        )\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(15, 2))\n",
    "        ax.axis('off')\n",
    "        ax.table(\n",
    "            cellText=table.values, \n",
    "            colLabels=table.columns, \n",
    "            rowLabels=[' '+str(aux)+' ' for aux in range(1,7)], \n",
    "            colWidths = [0.06 for _ in table.columns],\n",
    "            cellColours = [\n",
    "                [\n",
    "                    colour_decide(\n",
    "                        float(val),\n",
    "                        overvoltage,\n",
    "                        params['std_number_soft'],\n",
    "                        params['std_number_hard']\n",
    "                    ) for val in row\n",
    "                ] for row in table.values\n",
    "            ],\n",
    "            cellLoc = 'center',\n",
    "            loc='center'\n",
    "        )\n",
    "        ax.set_title(\n",
    "            f\"{field_to_show} @ OV = {overvoltage} V\"\n",
    "        )\n",
    "        \n",
    "        report_pdf.add_plot(\n",
    "            fig,\n",
    "            horizontal_pos_frac=None,\n",
    "            vertical_pos_frac=tables_vertical_pos_frac[i],\n",
    "            plot_width_wrt_page_width=0.99,\n",
    "            horizontally_center=True\n",
    "        )\n",
    "\n",
    "    report_pdf.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Generate the cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params['generate_report']:\n",
    "\n",
    "    path_to_cover_pdf = os.path.join(\n",
    "        summary_dir,\n",
    "        'temp_cover.pdf'\n",
    "    )\n",
    "\n",
    "    cover_pdf = PDFGenerator(path_to_cover_pdf)\n",
    "\n",
    "    cover_pdf.add_text(\n",
    "        f\"Gain analysis report\",\n",
    "        horizontal_pos_frac=None,\n",
    "        vertical_pos_frac=0.95,\n",
    "        max_width_frac=0.9,\n",
    "        font_size=params['title_font_size'],\n",
    "        horizontally_center=True\n",
    "    )\n",
    "\n",
    "    clustered_boards_string = tools.get_string_of_contiguously_clustered_integers(\n",
    "        tools.cluster_integers_by_contiguity(list(output_dataframe.groupby('strip_ID').groups.keys()))\n",
    "    )\n",
    "\n",
    "    cover_pdf.add_text(\n",
    "        f\"Analyzed boards: {clustered_boards_string}\",\n",
    "        horizontal_pos_frac=None,\n",
    "        vertical_pos_frac=0.90,\n",
    "        max_width_frac=0.9,\n",
    "        font_size=params['subtitle_font_size'],\n",
    "        horizontally_center=True\n",
    "    )\n",
    "\n",
    "    cover_pdf.add_text(\n",
    "        f\"The results have been dumped to both, a CSV file \"\n",
    "        f\"('{params['output_dataframe_filename']}.csv') and a pickle file \"\n",
    "        f\"('{params['output_dataframe_filename']}.pkl'), saved alongside this\"\n",
    "        \" report.\", \n",
    "        horizontal_pos_frac=None,\n",
    "        vertical_pos_frac=0.80,\n",
    "        max_width_frac=0.9,\n",
    "        font_size=params['text_font_size'],\n",
    "        horizontally_center=True\n",
    "    )\n",
    "\n",
    "    # n_reliable_analyses[i] gives the number of SiPMs\n",
    "    # with analysis_reliability[i] equal to n, where\n",
    "    # n = 0, 1\n",
    "    n_reliable_analyses = {\n",
    "        i: np.count_nonzero(np.array(analysis_reliability) == i)\n",
    "        for i in range(2)\n",
    "    }\n",
    "\n",
    "    if sum(list(n_reliable_analyses.values())) == 0:\n",
    "        cover_pdf.add_text(\n",
    "            f\"All of the analyses have been tagged as reliable\",\n",
    "            horizontal_pos_frac=None,\n",
    "            vertical_pos_frac=0.71,\n",
    "            max_width_frac=0.9,\n",
    "            font_size=params['text_font_size'],\n",
    "            font_color=colors.green,\n",
    "            horizontally_center=True\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        cover_pdf.add_text(\n",
    "            f\"A total of {n_reliable_analyses[0]} (resp. {n_reliable_analyses[1]}) analyses,\"\n",
    "            f\" out of {len(gainmeas_objects)} - the {round(100.*n_reliable_analyses[0]/len(gainmeas_objects), ndigits=2)} %\"\n",
    "            f\"(resp. {round(100.*n_reliable_analyses[1]/len(gainmeas_objects), ndigits=2)} %)- \"\n",
    "            \"have been tagged as 0- (resp. 1-) reliable:\",\n",
    "            horizontal_pos_frac=None,\n",
    "            vertical_pos_frac=0.71,\n",
    "            max_width_frac=0.9,\n",
    "            font_size=params['text_font_size'],\n",
    "            font_color=colors.red,\n",
    "            horizontally_center=True\n",
    "        )\n",
    "\n",
    "        added_lines_so_far = tools.natural_numbers_generator()\n",
    "        added_lines_so_far_in_this_page = 0\n",
    "        fNewPage = False\n",
    "        aux_starting_vertical_pos_frac = {\n",
    "            True: 0.9, False: 0.67\n",
    "        }\n",
    "\n",
    "        for i in range(len(analysis_reliability)):\n",
    "            if analysis_reliability[i] < 2:\n",
    "                vertical_pos_frac = \\\n",
    "                    aux_starting_vertical_pos_frac[fNewPage] \\\n",
    "                        - (0.02 * (added_lines_so_far_in_this_page))\n",
    "\n",
    "                if vertical_pos_frac < 0.1:\n",
    "                    # Most of the times, the cover PDF will encompass\n",
    "                    # just one page. For very ill-formed cases, it can\n",
    "                    # go up to some pages (less than 10). That's why\n",
    "                    # I am not using the smart-close-page method here.\n",
    "                    cover_pdf.close_page_and_start_a_new_one()\n",
    "                    fNewPage = True\n",
    "\n",
    "                    added_lines_so_far_in_this_page = 0\n",
    "                    vertical_pos_frac = \\\n",
    "                        aux_starting_vertical_pos_frac[fNewPage]\n",
    "\n",
    "                cover_pdf.add_text(\n",
    "                    f\"{next(added_lines_so_far)}) {gainmeas_objects[i].get_title()}\",\n",
    "                    horizontal_pos_frac=None,\n",
    "                    vertical_pos_frac=vertical_pos_frac,\n",
    "                    max_width_frac=0.9,\n",
    "                    font_size=params['text_font_size']-4.,\n",
    "                    font_color={\n",
    "                        0: colors.red,\n",
    "                        1: colors.orange\n",
    "                    }[analysis_reliability[i]],\n",
    "                    horizontally_center=True\n",
    "                )\n",
    "\n",
    "                added_lines_so_far_in_this_page += 1\n",
    "\n",
    "    cover_pdf.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Join the PDF chunks and add the cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params['generate_report']:\n",
    "\n",
    "    aux_path_to_report_pdf = os.path.join(\n",
    "        summary_dir,\n",
    "        params['report_output_filename']\n",
    "    )\n",
    "\n",
    "    if params['verbose']:\n",
    "        print(\n",
    "            f\"Saving the report PDF to \"\n",
    "            f\"{os.path.abspath(aux_path_to_report_pdf)}\"\n",
    "        )\n",
    "\n",
    "    PDFGenerator.concatenate_PDFs(\n",
    "        [path_to_cover_pdf]+pdf_reports_filepaths,\n",
    "        aux_path_to_report_pdf\n",
    "    )\n",
    "\n",
    "    os.remove(path_to_cover_pdf)    \n",
    "    for filepath in pdf_reports_filepaths:\n",
    "        os.remove(filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "massibo_ana_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
